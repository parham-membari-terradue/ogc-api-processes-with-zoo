{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"OGC API Processes with ZOO-Project","text":""},{"location":"#background-on-zoo-project","title":"Background on ZOO-Project","text":"<p>The ZOO-Project is an open-source processing platform introduced in 2009, licensed under the MIT/X11 license. It facilitates integration and communication between existing software components using standards defined by the Open Geospatial Consortium (OGC).</p> <p>The platform aims to ensure that processing tasks follow the FAIR principles: Findable, Accessible, Interoperable, and Reproducible.</p> <p>The ZOO-Project supports the \"OGC API - Processes\" - Part 1 (Core) and Part 2 (Deploy, Replace, Undeploy) Standards.</p>"},{"location":"#background-on-ogc-api-processes","title":"Background on OGC API - Processes","text":""},{"location":"#introduction-to-ogc-api-processes","title":"Introduction to OGC API - Processes","text":"<p>The OGC API - Processes standard supports the wrapping of computational tasks into executable processes that can be offered by a server through a Web API and be invoked by a client application. It specifies a processing interface for communicating over a RESTful protocol using JavaScript Object Notation (JSON) encodings. The standard builds on concepts from the OGC Web Processing Service (WPS) 2.0 Interface Standard but provides a more modern approach, allowing for interaction with web resources using the OpenAPI specification. Importantly, it does not require implementation of a WPS interface.</p>"},{"location":"#use-cases-for-ogc-api-processes","title":"Use Cases for OGC API - Processes","text":"<p>Government agencies, private organizations, and academic institutions use the OGC API - Processes standard to provide access to geospatial algorithms for processing data, including data from sensors. This distributed approach to processing allows for more capacity to handle large datasets and perform complex computations. The standard facilitates integration into existing software packages and supports scalable workflows for processing geospatial data.</p>"},{"location":"#overview-of-ogc-api-processes-part-1-core","title":"Overview of \"OGC API - Processes - Part 1 - Core\"","text":"<p>The OGC API - Processes - Part 1: Core enables the execution of computational tasks such as raster algebra, geometry buffering, routing, constructive area geometry, and imagery analysis. It supports execution in two modes: synchronous, where the client waits for the execution to complete, and asynchronous, where the server processes the task in the background and the client periodically checks the status.</p> <p>The table below outlines the main resources defined by the OGC API - Processes - Part 1: Core standard:</p> Resource Path Purpose Landing page <code>/</code> Top-level resource serving as an entry point. Conformance declaration <code>/conformance</code> Information about the functionality supported by the server. API Definition <code>/api</code> Metadata about the API itself. Process list <code>/processes</code> Lists available processes with identifiers and links to descriptions. Process description <code>/processes/{processID}</code> Retrieves a process description. Process execution <code>/processes/{processID}/execution</code> (POST) Creates and executes a job. Job status info <code>/jobs/{jobID}</code> Retrieves information about the status of a job. Job results <code>/jobs/{jobID}/results</code> Retrieves the result(s) of a job. Job list <code>/jobs</code> Retrieves the list of jobs. Job Deletion <code>/jobs/{jobID}</code> (DELETE) Cancels and deletes a job."},{"location":"#overview-of-ogc-api-processes-part-2-deploy-replace-undeploy-dru","title":"Overview of \"OGC API - Processes - Part 2: Deploy, Replace, Undeploy (DRU)\"","text":"<p>The OGC API - Processes - Part 2 specification extends the Core standard by defining additional capabilities for managing processes. It allows users to deploy, replace, and undeploy computational processes dynamically. This specification is useful for scenarios where processes need to be updated or removed, providing more flexibility and control over the server's computational tasks.</p> <p>Here are the new resources introduced in Part 2:</p> Resource Path Purpose Deploy Process <code>/processes</code> (POST) Deploys a new process on the server. Replace Process <code>/processes/{processID}</code> (PUT) Replaces an existing process with a new version. Undeploy Process <code>/processes/{processID}</code> (DELETE) Removes an existing process from the server. Application Package (OGC AppPkg) <code>/processes/{processId}/package</code> Support accessing the OGC Application Package."},{"location":"#ogc-api-process-resources-combining-part-1-and-part-2","title":"OGC API - Process resources combining Part 1 and Part 2","text":"Resource Path Purpose Part Landing page <code>/</code> Top-level resource serving as an entry point. Part 1 Conformance declaration <code>/conformance</code> Information about the functionality supported by the server. Part 1 API Definition <code>/api</code> Metadata about the API itself. Part 1 Process list <code>/processes</code> Lists available processes with identifiers and links to descriptions. Part 1 Process description <code>/processes/{processID}</code> Retrieves detailed information about a specific process. Part 1 Process execution <code>/processes/{processID}/execution</code> (POST) Executes a process, creating a job. Part 1 Deploy Process <code>/processes</code> (POST) Deploys a new process on the server. Part 2 Replace Process <code>/processes/{processID}</code> (PUT) Replaces an existing process with a new version. Part 2 Undeploy Process <code>/processes/{processID}</code> (DELETE) Removes an existing process from the server. Part 2 Application Package (OGC AppPkg) <code>/processes/{processId}/package</code> Support accessing the OGC Application Package. Part 2 Job status info <code>/jobs/{jobID}</code> Retrieves the current status of a job. Part 1 Job results <code>/jobs/{jobID}/results</code> Retrieves the results of a job. Part 1 Job list <code>/jobs</code> Retrieves a list of submitted jobs. Part 1 Job deletion <code>/jobs/{jobID}</code> (DELETE) Cancels and deletes a job. Part 1"},{"location":"#relation-to-other-ogc-standards","title":"Relation to Other OGC Standards","text":"<p>The OGC API - Processes standard modernizes and extends the capabilities offered by the OGC WPS. While the WPS standard provided a standardized interface for accessing computational services, the OGC API - Processes standard adopts a resource-oriented approach leveraging the OpenAPI specification. This results in better integration with modern web technologies and programming practices, addressing all the use cases supported by WPS and enabling more flexible and robust processing capabilities.</p>"},{"location":"#learning-module-overview","title":"Learning Module overview","text":""},{"location":"#tutorials","title":"Tutorials","text":"<p>This series of tutorials provides a step-by-step guide to using the OGC API - Processes standard, covering the core functionalities from listing available processes to accessing the results of executed jobs. Each tutorial is designed to help you understand and implement the standard's capabilities in a practical way. The tutorials are provided with the following Jupyter Notebooks:</p> <ol> <li>Deploy an application package.ipynb</li> <li>List the deployed processes.ipynb</li> <li>Describe the process.ipynb</li> <li>Execute the process and monitor its job execution.ipynb</li> </ol>"},{"location":"#key-functionalities","title":"Key Functionalities","text":"<p>Following these tutorials, the user will be able to cover all these key functionalities: </p> <ul> <li>List Available Processes: Learn how to retrieve the list of processes offered by the server. This step provides an overview of the available computational tasks, including process identifiers, titles, and descriptions.</li> <li>Deployment: Discover how to deploy a new process, such as a custom application package using Common Workflow Language (CWL). This tutorial explains the encoding options for deployment requests and how to handle deployment responses.</li> <li>Process Description: Understand how to obtain detailed descriptions of individual processes, including their inputs, outputs, and supported execution modes. This step provides insight into how to configure and execute specific tasks.</li> <li>Execution: Learn how to execute a process using the <code>/processes/{processID}/execution</code> endpoint. The tutorial covers submitting the execution request, passing inputs, and handling different execution modes.</li> <li>Monitor Execution: Discover how to track the progress of a submitted job. This tutorial explains how to monitor job status, retrieve progress updates, and check for completion.</li> <li>Access Results: Learn how to retrieve the results of a completed job. The tutorial covers accessing outputs like STAC catalogs or other data formats, allowing you to analyze the processed data.</li> <li>Job Management: Understand how to manage jobs, including listing all jobs, cancelling running jobs, and deleting completed or failed jobs. This tutorial explains how to maintain the server's job history and resource usage.</li> </ul>"},{"location":"deploy-application/","title":"Deploy the Application Package","text":"<p>Deploying an Application Package using the OGC API Processes API uses the API resource highlighted in the table below:</p> Resource Path Purpose Part Landing page <code>/</code> Top-level resource serving as an entry point. Part 1 Conformance declaration <code>/conformance</code> Information about the functionality supported by the server. Part 1 API Definition <code>/api</code> Metadata about the API itself. Part 1 Process list <code>/processes</code> Lists available processes with identifiers and links to descriptions. Part 1 Process description <code>/processes/{processID}</code> Retrieves detailed information about a specific process. Part 1 Process execution <code>/processes/{processID}/execution</code> (POST) Executes a process, creating a job. Part 1 Deploy Process <code>/processes</code> (POST) Deploys a new process on the server. Part 2 Replace Process <code>/processes/{processID}</code> (PUT) Replaces an existing process with a new version. Part 2 Undeploy Process <code>/processes/{processID}</code> (DELETE) Removes an existing process from the server. Part 2 EO Application Package <code>/processes/{processID}/package</code> Get the EOAP associated with a deployed process. Part 2 Job status info <code>/jobs/{jobID}</code> Retrieves the current status of a job. Part 1 Job results <code>/jobs/{jobID}/results</code> Retrieves the results of a job. Part 1 Job list <code>/jobs</code> Retrieves a list of submitted jobs. Part 1 Job deletion <code>/jobs/{jobID}</code> (DELETE) Cancels and deletes a job. Part 1 <p>This resource permits the deployment of the an Application Package and provide two options for the <code>Content-Type</code>.</p>"},{"location":"deploy-application/#hands-on-deploy-the-water_bodies-application-package","title":"Hands-on - Deploy the water_bodies Application Package","text":"<p>Encoding Options</p> <p>The deployment can use two encodings that are based on the same CWL conformance class. Both methods utilize the same water_bodies.cwl file, but the way the file is provided differs: - OGC Application Package Encoding (application/ogcapppkg+json): This method allows you to reference the CWL file by providing its location, rather than including the file's content in the request. - CWL Encoding (application/cwl+yaml): This method requires the CWL file content to be included directly in the request body.</p> <p>Request Configuration</p> <p>When selecting a content type, the request body text area updates to contain a relevant payload template for that encoding. Warning: If the payload is manually edited, switching to a different encoding may not refresh the text area. In this case, the Reset button can be used to restore the appropriate template.</p> <p>Server Response</p> <p>After executing the deployment request, the server responds with a process summary similar to the one obtained from the previous process listing endpoint. The server\u2019s response includes a Location header containing the URL to access the detailed process description.</p> <p>Next Steps </p> <p>You can either: - Return to the list of available processes to verify the newly deployed process. - Proceed to the next step to review the process description in detail</p>"},{"location":"deploy-application/#setup","title":"Setup","text":"<p>Lists available processes in the <code>acme</code> namespace.</p> <p>NOTE:: if the <code>acme</code> namespace does not exist, ZOO Project will create it.</p> <pre><code>import requests\nimport json\nimport yaml\nimport time\nimport os\nimport sys\nfrom loguru import logger\nfrom pystac.item_collection import ItemCollection\nfrom pprint import pprint\nnamespace = \"acme\"\n\nogc_api_endpoint = f\"http://zoo-project-dru-service/{namespace}/ogc-api\"\n\nr = requests.get(f\"{ogc_api_endpoint}/processes\")\n\nr.status_code\n</code></pre> <pre><code>200\n</code></pre> <p>If the application package was deployed previously, delete it.</p> <pre><code>def undeploy(process_id):\n\n    r = requests.delete(f\"{ogc_api_endpoint}/processes/{process_id}\")\n\n    return r\n\napp_package_entry_point = \"water-bodies\"\n\nr = undeploy(app_package_entry_point)\n\nr.status_code\n</code></pre> <pre><code>404\n</code></pre>"},{"location":"deploy-application/#ogc-application-package-encoding-applicationogcapppkgjson","title":"OGC Application Package Encoding (application/ogcapppkg+json)","text":"<p>OGC Application Package Encoding (application/ogcapppkg+json): This method allows you to reference the CWL file by providing its location, rather than including the file's content in the request.</p> <pre><code>app_package_entry_point = \"water-bodies\"\ndef app_package_deployment(app_package_entry_point, app_package_url):  \n  headers = {\"accept\": \"application/json\", \n          \"Content-Type\": \"application/ogcapppkg+json\"}\n  response = requests.post(\n\n      f\"{ogc_api_endpoint}/processes/?w={app_package_entry_point}\",\n      headers=headers,\n      json = {\n        \"executionUnit\": {\n          \"href\": app_package_url,\n          \"type\": \"application/cwl\"\n        }\n      }\n  )\n  return response\n\ndef check_app_package_deployment(app_package_entry_point):\n    r = requests.get(f\"{ogc_api_endpoint}/processes/\")\n\n    if r.status_code == 200:\n        # Parse the JSON response\n        all_processes = r.json()\n        for process in all_processes.get(\"processes\", []):\n          if process.get(\"id\") in [app_package_entry_point]:\n              logger.info(f\"Application package {app_package_entry_point} is already deployed.\")\n              return True\n          else:\n              logger.warning(f\"{app_package_entry_point} still not deployed.\")\n              return False\n    else:\n        logger.error(f\"Failed to retrieve processes. Status code: {r.status_code}\")\n        sys.exit(1)\n\ndef get_latest_application_package_version(repository_owner, repo_name):\n\n    url = f\"https://api.github.com/repos/{repository_owner}/{repo_name}/releases/latest\"\n    response = requests.get(url)\n    response.raise_for_status()  # raise error if request failed\n\n    latest_tag = response.json().get(\"tag_name\")\n    return latest_tag\n</code></pre> <pre><code>app_package_entry_point = \"water-bodies\"\nis_package_deployed = check_app_package_deployment(app_package_entry_point)\nrepo_name = \"mastering-app-package\"\nrepository_owner = os.environ.get(\"REPOSITORY_OWNER\", \"eoap\")\nlatest_application_package_version = get_latest_application_package_version(repository_owner, repo_name)\nlogger.info(f\"Latest version is:  {latest_application_package_version}\")\napp_package_url = f\"https://github.com/{repository_owner}/mastering-app-package/releases/download/{latest_application_package_version}/app-water-bodies-cloud-native.{latest_application_package_version}.cwl\"\nif not is_package_deployed:\n\n    response= app_package_deployment(app_package_entry_point, app_package_url)\n    pprint(response.json())\n</code></pre> <pre><code>\u001b[32m2025-08-20 13:40:19.690\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcheck_app_package_deployment\u001b[0m:\u001b[36m29\u001b[0m - \u001b[33m\u001b[1mwater-bodies still not deployed.\u001b[0m\n\u001b[32m2025-08-20 13:40:19.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m&lt;module&gt;\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mLatest version is:  1.1.1\u001b[0m\n\n\n{'description': 'Water bodies detection based on NDWI and otsu threshold '\n                'applied to Sentinel-2 COG STAC items',\n 'id': 'water-bodies',\n 'jobControlOptions': ['async-execute', 'dismiss'],\n 'links': [{'href': 'http://localhost:8080/acme/ogc-api/processes/water-bodies/execution',\n            'rel': 'http://www.opengis.net/def/rel/ogc/1.0/execute',\n            'title': 'Execute End Point',\n            'type': 'application/json'}],\n 'metadata': [{'role': 'https://schema.org/softwareVersion', 'value': '1.1.1'},\n              {'role': 'https://schema.org/author',\n               'value': {'@context': 'https://schema.org',\n                         '@type': 'Person',\n                         's.affiliation': 'ACME',\n                         's.email': 'jane.doe@acme.earth',\n                         's.name': 'Jane Doe'}}],\n 'mutable': True,\n 'outputTransmission': ['value', 'reference'],\n 'title': 'Water bodies detection based on NDWI and otsu threshold',\n 'version': '1.1.1'}\n</code></pre> <pre><code>dict(response.headers)\n</code></pre> <pre><code>{'Date': 'Wed, 20 Aug 2025 13:40:19 GMT',\n 'Server': 'Apache/2.4.41 (Ubuntu)',\n 'X-Powered-By': 'ZOO-Project-DRU',\n 'X-Also-Powered-By': 'jwt.securityIn',\n 'X-Also-Also-Powered-By': 'dru.securityIn',\n 'Location': 'http://localhost:8080/acme/ogc-api/processes/water-bodies',\n 'Keep-Alive': 'timeout=5, max=100',\n 'Connection': 'Keep-Alive',\n 'Transfer-Encoding': 'chunked',\n 'Content-Type': 'application/json;charset=UTF-8'}\n</code></pre>"},{"location":"deploy-application/#cwl-encoding-applicationcwlyaml","title":"CWL Encoding (application/cwl+yaml)","text":"<p>This method requires the CWL file content to be included directly in the request body.</p> <p>If the application package was deployed previously, delete it.</p> <pre><code>app_package_entry_point = \"water-bodies\"\n\nr = undeploy(app_package_entry_point)\nr.status_code\n</code></pre> <pre><code>204\n</code></pre> <p>Download the application package from https://github.com/eoap/mastering-app-package/releases/download/1.0.0/app-water-bodies-cloud-native.1.0.0.cwl</p> <pre><code>r = requests.get(app_package_url)\n\napp_package_content  = yaml.safe_load(r.content)\n\napp_package_content\n</code></pre> <pre><code>{'cwlVersion': 'v1.0',\n '$namespaces': {'s': 'https://schema.org/'},\n 's:softwareVersion': '1.1.1',\n 'schemas': ['http://schema.org/version/9.0/schemaorg-current-http.rdf'],\n '$graph': [{'class': 'Workflow',\n   'id': 'water-bodies',\n   'label': 'Water bodies detection based on NDWI and otsu threshold',\n   'doc': 'Water bodies detection based on NDWI and otsu threshold applied to Sentinel-2 COG STAC items',\n   'requirements': [{'class': 'ScatterFeatureRequirement'},\n    {'class': 'SubworkflowFeatureRequirement'}],\n   'inputs': {'aoi': {'label': 'area of interest',\n     'doc': 'area of interest as a bounding box',\n     'type': 'string'},\n    'epsg': {'label': 'EPSG code',\n     'doc': 'EPSG code',\n     'type': 'string',\n     'default': 'EPSG:4326'},\n    'stac_items': {'label': 'Sentinel-2 STAC items',\n     'doc': 'list of Sentinel-2 COG STAC items',\n     'type': 'string[]'},\n    'bands': {'label': 'bands used for the NDWI',\n     'doc': 'bands used for the NDWI',\n     'type': 'string[]',\n     'default': ['green', 'nir']}},\n   'outputs': [{'id': 'stac_catalog',\n     'outputSource': ['node_stac/stac_catalog'],\n     'type': 'Directory'}],\n   'steps': {'node_water_bodies': {'run': '#detect_water_body',\n     'in': {'item': 'stac_items',\n      'aoi': 'aoi',\n      'epsg': 'epsg',\n      'bands': 'bands'},\n     'out': ['detected_water_body'],\n     'scatter': 'item',\n     'scatterMethod': 'dotproduct'},\n    'node_stac': {'run': '#stac',\n     'in': {'item': 'stac_items',\n      'rasters': {'source': 'node_water_bodies/detected_water_body'}},\n     'out': ['stac_catalog']}}},\n  {'class': 'Workflow',\n   'id': 'detect_water_body',\n   'label': 'Water body detection based on NDWI and otsu threshold',\n   'doc': 'Water body detection based on NDWI and otsu threshold',\n   'requirements': [{'class': 'ScatterFeatureRequirement'}],\n   'inputs': {'aoi': {'doc': 'area of interest as a bounding box',\n     'type': 'string'},\n    'epsg': {'doc': 'EPSG code', 'type': 'string', 'default': 'EPSG:4326'},\n    'bands': {'doc': 'bands used for the NDWI', 'type': 'string[]'},\n    'item': {'doc': 'STAC item', 'type': 'string'}},\n   'outputs': [{'id': 'detected_water_body',\n     'outputSource': ['node_otsu/binary_mask_item'],\n     'type': 'File'}],\n   'steps': {'node_crop': {'run': '#crop',\n     'in': {'item': 'item', 'aoi': 'aoi', 'epsg': 'epsg', 'band': 'bands'},\n     'out': ['cropped'],\n     'scatter': 'band',\n     'scatterMethod': 'dotproduct'},\n    'node_normalized_difference': {'run': '#norm_diff',\n     'in': {'rasters': {'source': 'node_crop/cropped'}},\n     'out': ['ndwi']},\n    'node_otsu': {'run': '#otsu',\n     'in': {'raster': {'source': 'node_normalized_difference/ndwi'}},\n     'out': ['binary_mask_item']}}},\n  {'class': 'CommandLineTool',\n   'id': 'crop',\n   'requirements': {'InlineJavascriptRequirement': {},\n    'EnvVarRequirement': {'envDef': {'PATH': '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n      'PYTHONPATH': '/app'}},\n    'ResourceRequirement': {'coresMax': 1, 'ramMax': 512}},\n   'hints': {'DockerRequirement': {'dockerPull': 'ghcr.io/parham-membari-terradue/mastering-app-package/crop@sha256:0fc019633a1968a611a07f335ddcc9a478f6971c72757a57e060423fae57473e'}},\n   'baseCommand': ['python', '-m', 'app'],\n   'arguments': [],\n   'inputs': {'item': {'type': 'string',\n     'inputBinding': {'prefix': '--input-item'}},\n    'aoi': {'type': 'string', 'inputBinding': {'prefix': '--aoi'}},\n    'epsg': {'type': 'string', 'inputBinding': {'prefix': '--epsg'}},\n    'band': {'type': 'string', 'inputBinding': {'prefix': '--band'}}},\n   'outputs': {'cropped': {'outputBinding': {'glob': '*.tif'},\n     'type': 'File'}}},\n  {'class': 'CommandLineTool',\n   'id': 'norm_diff',\n   'requirements': {'InlineJavascriptRequirement': {},\n    'EnvVarRequirement': {'envDef': {'PATH': '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n      'PYTHONPATH': '/app'}},\n    'ResourceRequirement': {'coresMax': 1, 'ramMax': 512}},\n   'hints': {'DockerRequirement': {'dockerPull': 'ghcr.io/parham-membari-terradue/mastering-app-package/norm_diff@sha256:e46491095215833722db2c3d3c24feae381c1008981ae3508973b6aa1f5a880a'}},\n   'baseCommand': ['python', '-m', 'app'],\n   'arguments': [],\n   'inputs': {'rasters': {'type': 'File[]', 'inputBinding': {'position': 1}}},\n   'outputs': {'ndwi': {'outputBinding': {'glob': '*.tif'}, 'type': 'File'}}},\n  {'class': 'CommandLineTool',\n   'id': 'otsu',\n   'requirements': {'InlineJavascriptRequirement': {},\n    'EnvVarRequirement': {'envDef': {'PATH': '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n      'PYTHONPATH': '/app'}},\n    'ResourceRequirement': {'coresMax': 1, 'ramMax': 512}},\n   'hints': {'DockerRequirement': {'dockerPull': 'ghcr.io/parham-membari-terradue/mastering-app-package/otsu@sha256:f026bcac96c9bf1ce486855ea6e8fd27ccc501e82dbc6837021c32d9708d097a'}},\n   'baseCommand': ['python', '-m', 'app'],\n   'arguments': [],\n   'inputs': {'raster': {'type': 'File', 'inputBinding': {'position': 1}}},\n   'outputs': {'binary_mask_item': {'outputBinding': {'glob': '*.tif'},\n     'type': 'File'}}},\n  {'class': 'CommandLineTool',\n   'id': 'stac',\n   'requirements': {'InlineJavascriptRequirement': {},\n    'EnvVarRequirement': {'envDef': {'PATH': '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n      'PYTHONPATH': '/app'}},\n    'ResourceRequirement': {'coresMax': 1, 'ramMax': 512}},\n   'hints': {'DockerRequirement': {'dockerPull': 'ghcr.io/parham-membari-terradue/mastering-app-package/stac@sha256:c687a9f18ebb9352a150bb7ac2d687ec9e08e2f4ef2519da342012895dbb693e'}},\n   'baseCommand': ['python', '-m', 'app'],\n   'arguments': [],\n   'inputs': {'item': {'type': {'type': 'array',\n      'items': 'string',\n      'inputBinding': {'prefix': '--input-item'}}},\n    'rasters': {'type': {'type': 'array',\n      'items': 'File',\n      'inputBinding': {'prefix': '--water-body'}}}},\n   'outputs': {'stac_catalog': {'outputBinding': {'glob': '.'},\n     'type': 'Directory'}}}],\n 's:codeRepository': {'URL': 'https://github.com/parham-membari-terradue/mastering-app-package.git'},\n 's:author': [{'class': 's:Person',\n   's.name': 'Jane Doe',\n   's.email': 'jane.doe@acme.earth',\n   's.affiliation': 'ACME'}]}\n</code></pre> <pre><code>def app_package_deployment_cwl_encoding(app_package_entry_point, app_package_content):  \n\n    headers = {\"accept\": \"application/json\", \n            \"Content-Type\": \"application/cwl+yaml\"}\n\n    response = requests.post(\n        f\"{ogc_api_endpoint}/processes?w={app_package_entry_point}\",\n        headers=headers,\n        json=app_package_content\n    )\n    print(response.status_code)\n    return response\n</code></pre> <pre><code>app_package_entry_point = \"water-bodies\"\nis_package_deployed = check_app_package_deployment(app_package_entry_point)\nif not is_package_deployed:\n    response = app_package_deployment_cwl_encoding(app_package_entry_point, app_package_content)\n    pprint(response.json())\n</code></pre> <pre><code>\u001b[32m2025-08-20 13:40:49.695\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcheck_app_package_deployment\u001b[0m:\u001b[36m29\u001b[0m - \u001b[33m\u001b[1mwater-bodies still not deployed.\u001b[0m\n\n\n201\n{'description': 'Water bodies detection based on NDWI and otsu threshold '\n                'applied to Sentinel-2 COG STAC items',\n 'id': 'water-bodies',\n 'jobControlOptions': ['async-execute', 'dismiss'],\n 'links': [{'href': 'http://localhost:8080/acme/ogc-api/processes/water-bodies/execution',\n            'rel': 'http://www.opengis.net/def/rel/ogc/1.0/execute',\n            'title': 'Execute End Point',\n            'type': 'application/json'}],\n 'metadata': [{'role': 'https://schema.org/softwareVersion', 'value': '1.1.1'},\n              {'role': 'https://schema.org/author',\n               'value': {'@context': 'https://schema.org',\n                         '@type': 'Person',\n                         's.affiliation': 'ACME',\n                         's.email': 'jane.doe@acme.earth',\n                         's.name': 'Jane Doe'}}],\n 'mutable': True,\n 'outputTransmission': ['value', 'reference'],\n 'title': 'Water bodies detection based on NDWI and otsu threshold',\n 'version': '1.1.1'}\n</code></pre> <pre><code>dict(response.headers)\n</code></pre> <pre><code>{'Date': 'Wed, 20 Aug 2025 13:40:49 GMT',\n 'Server': 'Apache/2.4.41 (Ubuntu)',\n 'X-Powered-By': 'ZOO-Project-DRU',\n 'X-Also-Powered-By': 'jwt.securityIn',\n 'X-Also-Also-Powered-By': 'dru.securityIn',\n 'Location': 'http://localhost:8080/acme/ogc-api/processes/water-bodies',\n 'Keep-Alive': 'timeout=5, max=100',\n 'Connection': 'Keep-Alive',\n 'Transfer-Encoding': 'chunked',\n 'Content-Type': 'application/json;charset=UTF-8'}\n</code></pre> <p>Next Steps </p> <p>You can either: - Return to the list of available processes to verify the newly deployed process. - Proceed to the next step to review the process description in detail</p>"},{"location":"describe-process/","title":"Describe the process","text":"<p>To describe a process, the OGC API Processes API uses the resource highlighted in the table below:</p> Resource Path Purpose Part Landing page <code>/</code> Top-level resource serving as an entry point. Part 1 Conformance declaration <code>/conformance</code> Information about the functionality supported by the server. Part 1 API Definition <code>/api</code> Metadata about the API itself. Part 1 Process list <code>/processes</code> Lists available processes with identifiers and links to descriptions. Part 1 Process description <code>/processes/{processID}</code> Retrieves detailed information about a specific process. Part 1 Process execution <code>/processes/{processID}/execution</code> (POST) Executes a process, creating a job. Part 1 Deploy Process <code>/processes</code> (POST) Deploys a new process on the server. Part 2 Replace Process <code>/processes/{processID}</code> (PUT) Replaces an existing process with a new version. Part 2 Undeploy Process <code>/processes/{processID}</code> (DELETE) Removes an existing process from the server. Part 2 EO Application Package <code>/processes/{processID}/package</code> Get the EOAP associated with a deployed process. Part 2 Job status info <code>/jobs/{jobID}</code> Retrieves the current status of a job. Part 1 Job results <code>/jobs/{jobID}/results</code> Retrieves the results of a job. Part 1 Job list <code>/jobs</code> Retrieves a list of submitted jobs. Part 1 Job deletion <code>/jobs/{jobID}</code> (DELETE) Cancels and deletes a job. Part 1 <pre><code>import requests\n\nnamespace = \"acme\"  # Replace with your namespace\nogc_api_endpoint = f\"http://zoo-project-dru-service/{namespace}/ogc-api\"\n</code></pre> <p>In the cell below, the user can examine the metadata of a specific process that has already been deployed on the OGC API endpoint.</p> <pre><code>process_id = \"water-bodies\"  \n\n\n# Make a GET request to retrieve the process description\nresponse = requests.get(f\"{ogc_api_endpoint}/processes/{process_id}\")\n\n# Check if the request was successful\nif response.status_code == 200:\n    # Parse the JSON response\n    process_description = response.json()\n\n    # Display the process details\n    print(f\"Process ID: {process_description.get('id')}\")\n    print(f\"Title: {process_description.get('title')}\")\n    print(f\"Description: {process_description.get('description')}\")\n    print(f\"Version: {process_description.get('version')}\")\n    print(f\"Mutable: {process_description.get('mutable')}\")\n\n    # Display inputs\n    print(\"\\nInputs:\")\n    for input_id, input_details in process_description.get(\"inputs\", {}).items():\n        print(f\"  - {input_id}:\")\n        print(f\"    Title: {input_details.get('title')}\")\n        print(f\"    Description: {input_details.get('description')}\")\n        print(f\"    Type: {input_details.get('schema', {}).get('type')}\")\n        print(f\"    Default: {input_details.get('schema', {}).get('default', 'N/A')}\")\n\n    # Display outputs\n    print(\"\\nOutputs:\")\n    for output_id, output_details in process_description.get(\"outputs\", {}).items():\n        print(f\"  - {output_id}:\")\n        print(f\"    Title: {output_details.get('title')}\")\n        print(f\"    Description: {output_details.get('description')}\")\nelse:\n    print(f\"Failed to retrieve process description. Status code: {response.status_code}\")\n</code></pre> <pre><code>Process ID: water-bodies\nTitle: Water bodies detection based on NDWI and otsu threshold\nDescription: Water bodies detection based on NDWI and otsu threshold applied to Sentinel-2 COG STAC items\nVersion: 1.0.0\nMutable: True\n\nInputs:\n  - aoi:\n    Title: area of interest\n    Description: area of interest as a bounding box\n    Type: string\n    Default: N/A\n  - bands:\n    Title: bands used for the NDWI\n    Description: bands used for the NDWI\n    Type: string\n    Default: ['green', 'nir']\n  - epsg:\n    Title: EPSG code\n    Description: EPSG code\n    Type: string\n    Default: EPSG:4326\n  - stac_items:\n    Title: Sentinel-2 STAC items\n    Description: list of Sentinel-2 COG STAC items\n    Type: string\n    Default: N/A\n\nOutputs:\n  - stac_catalog:\n    Title: stac_catalog\n    Description: None\n</code></pre>"},{"location":"describe-process/#explanation","title":"Explanation","text":"<p>Fetching Process Description:</p> <p>The script sends a GET request to the <code>/processes/{process_id}</code> endpoint to retrieve the description.</p> <p>The process ID (e.g., \"water-bodies\") is used to specify the process for which you want to get the description.</p> <p>Displaying Process Details:</p> <p>The response is parsed to extract details such as id, title, description, version, and whether the process is mutable. The script then displays the inputs and outputs associated with the process, including their title, description, and type.</p>"},{"location":"describe-process/#understanding-the-output","title":"Understanding the Output","text":"<p>Process Information:</p> <ul> <li>id: Unique identifier for the process.</li> <li>title and description: Provide details about the process's functionality.</li> <li>version: The version number of the process.</li> <li>mutable: Indicates whether the process can be modified or redeployed.</li> </ul> <p>Inputs and Outputs:</p> <p>Lists the parameters needed for the process execution (inputs) and what the process produces (outputs).</p> <p>Each input has attributes such as title, description, type, and default value.</p> <p>Outputs describe what will be produced by the process execution.</p>"},{"location":"describe-process/#troubleshooting","title":"Troubleshooting","text":"<p>If the script fails to retrieve the process description, ensure that: - The ZOO-Project OGC API server is running and accessible. - The specified process ID is correct and corresponds to an existing process. - The namespace is set correctly.</p>"},{"location":"describe-process/#next-steps","title":"Next Steps","text":"<p>After retrieving the process description, you can:</p> <ul> <li>Execute the process using the inputs described.</li> <li>Monitor the process execution to check its status.</li> <li>Retrieve the results once the process execution is complete.</li> </ul> <p>This tutorial provides the necessary steps to retrieve and understand the details of a deployed process using the ZOO-Project's OGC API.</p>"},{"location":"execute-monitor-process/","title":"Execute the process and monitor the execution","text":"<p>To submit an execution request of a deployed process and monitor it, the OGC API Processes API uses the resource highlighted in the table below:</p> Resource Path Purpose Part Landing page <code>/</code> Top-level resource serving as an entry point. Part 1 Conformance declaration <code>/conformance</code> Information about the functionality supported by the server. Part 1 API Definition <code>/api</code> Metadata about the API itself. Part 1 Process list <code>/processes</code> Lists available processes with identifiers and links to descriptions. Part 1 Process description <code>/processes/{processID}</code> Retrieves detailed information about a specific process. Part 1 Process execution <code>/processes/{processID}/execution</code>(POST) Executes a process, creating a job. Part 1 Deploy Process <code>/processes</code> (POST) Deploys a new process on the server. Part 2 Replace Process <code>/processes/{processID}</code> (PUT) Replaces an existing process with a new version. Part 2 Undeploy Process <code>/processes/{processID}</code> (DELETE) Removes an existing process from the server. Part 2 EO Application Package <code>/processes/{processID}/package</code> Get the EOAP associated with a deployed process. Part 2 Job status info <code>/jobs/{jobID}</code> Retrieves the current status of a job. Part 1 Job results <code>/jobs/{jobID}/results</code> Retrieves the results of a job. Part 1 Job list <code>/jobs</code> Retrieves a list of submitted jobs. Part 1 Job deletion <code>/jobs/{jobID}</code> (DELETE) Cancels and deletes a job. Part 1 <pre><code>import os\nfrom pprint import pprint\nimport requests\nimport time\nimport json\nfrom pystac.item_collection import ItemCollection\nfrom urllib.parse import urljoin, urlparse\nfrom ogc_api_client.api_client import Configuration\nfrom ogc_api_client.api_client_wrapper import ApiClientWrapper\nfrom ogc_api_client.models.status_info import StatusInfo, StatusCode\nfrom typing import Dict, Optional\nfrom fs_s3fs import S3FS\nfrom loguru import logger\nimport rasterio\n\n\nnamespace = \"acme\"\n\nogc_api_endpoint = f\"http://zoo-project-dru-service/{namespace}/ogc-api\"\n</code></pre> <p>Define the input data for the execution:</p> <pre><code>data = {\n    \"inputs\": {\n        \"stac_items\": [\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/landsat-c2-l2/items/LC08_L2SP_044032_20231208_02_T1\",\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/landsat-c2-l2/items/LC08_L2SP_043033_20231201_02_T1\"\n        ],\n        \"aoi\": \"-121.399,39.834,-120.74,40.472\",\n        \"epsg\": \"EPSG:4326\",\n        \"bands\": [\n            \"green\",\n            \"nir08\"\n        ]\n    }\n}\n</code></pre> <p>In the cell below, the user will configure the API client settings and initialize a client object using ApiClientWrapper. A request header will also be specified.</p> <pre><code>configuration = Configuration(\n    host=ogc_api_endpoint,\n)\nclient = ApiClientWrapper(configuration=configuration)\n\nheaders = {\n    \"accept\": \"*/*\",\n    \"Prefer\": \"respond-async;return=representation\",\n    \"Content-Type\": \"application/json\"\n}\n</code></pre> <p>Submit a water-bodies detection job to the OGC API endpoint and retrieve the job ID for monitoring</p> <pre><code>process_id = \"water-bodies\"  # Replace with your process ID if different\n\n# Submit the processing request\ncontent = client.execute_simple(process_id=process_id, execute=data, _headers=headers)\npprint(content)\nif isinstance(content, StatusInfo):\n    # Parse the response to get the job ID\n    job_id = content.job_id\n    print(f\"Job submitted successfully. Job ID: {job_id}\")\n    status_location = next((link.href for link in content.links if link.rel == 'monitor'), None)\n    if not status_location:\n        status_location = f\"{ogc_api_endpoint}/jobs/{job_id}\"\n\n    print(f\"Monitor job status at: {status_location}\")\nelse:\n    print(f\"Failed to submit job. Status code: {content.status}\")\n    print(\"Response:\", content.text)\n    raise ValueError(f\"Failed to submit job. Status code: {content.status}\")\n</code></pre> <pre><code>Job submitted successfully. Job ID: 68046976-7dcb-11f0-90ac-2a20aea25780\nMonitor job status at: http://zoo-project-dru-service/acme/ogc-api/jobs/68046976-7dcb-11f0-90ac-2a20aea25780\n</code></pre> <p>Monitor the Job Status</p> <pre><code>print(f\"\\nMonitoring job status (job ID: {job_id})...\")\n\nwhile True:\n    status = client.get_status(job_id=job_id)\n\n    if status:\n        print(f\"Job status: {status.status}\")\n\n        # Check if the job is completed (either successful or failed)\n        if status.status in [StatusCode.SUCCESSFUL, StatusCode.FAILED]:\n            break\n    else:\n        print(f\"Failed to get job status.\")\n        break\n\n    # Wait for a few seconds before checking again\n    time.sleep(10)\n\nif status and status.status == StatusCode.SUCCESSFUL:\n    # print(status)\n    print(\"\\nJob completed successfully. Retrieving results...\")\n    result = client.get_result(job_id=job_id)\n    print(result)\n    stac_feature_collection = result.get(\"stac_catalog\").actual_instance.value.oneof_schema_2_validator\n    print(\"STAC item collection:\", stac_feature_collection)\nelse:\n    print(\"\\nJob did not complete successfully.\")\n</code></pre> <pre><code>Monitoring job status...\nJob status: running\nJob status: running\nJob status: running\nJob status: running\nJob status: running\nJob status: running\nJob status: running\nJob status: running\nJob status: running\nJob status: successful\n\nJob completed successfully. Retrieving results...\nSTAC Catalog URI: {'type': 'FeatureCollection', 'features': [{'type': 'Feature', 'stac_version': '1.0.0', 'id': 'LC08_L2SP_044032_20231208_02_T1', 'properties': {'proj:epsg': 32610, 'proj:geometry': {'type': 'Polygon', 'coordinates': [[[636975.0, 4410555.0], [691605.0, 4410555.0], [691605.0, 4482615.0], [636975.0, 4482615.0], [636975.0, 4410555.0]]]}, 'proj:bbox': [636975.0, 4410555.0, 691605.0, 4482615.0], 'proj:shape': [2402, 1821], 'proj:transform': [30.0, 0.0, 636975.0, 0.0, -30.0, 4482615.0, 0.0, 0.0, 1.0], 'datetime': '2023-12-08T18:45:23.598169Z'}, 'geometry': {'type': 'Polygon', 'coordinates': [[[-121.39922829056682, 39.83396419450036], [-120.76118304700903, 39.82340258564599], [-120.73977187420928, 40.47213091315636], [-121.38391140352763, 40.482936393990066], [-121.39922829056682, 39.83396419450036]]]}, 'links': [{'rel': 'collection', 'href': 's3://results/68046976-7dcb-11f0-90ac-2a20aea25780/68046976-7dcb-11f0-90ac-2a20aea25780/collection.json', 'type': 'application/json', 'title': 'Processing results'}, {'rel': 'root', 'href': 's3://results/68046976-7dcb-11f0-90ac-2a20aea25780/catalog.json', 'type': 'application/json'}, {'rel': 'self', 'href': 's3://results/68046976-7dcb-11f0-90ac-2a20aea25780/68046976-7dcb-11f0-90ac-2a20aea25780/LC08_L2SP_044032_20231208_02_T1/LC08_L2SP_044032_20231208_02_T1.json', 'type': 'application/json'}, {'rel': 'parent', 'href': 's3://results/68046976-7dcb-11f0-90ac-2a20aea25780/68046976-7dcb-11f0-90ac-2a20aea25780/collection.json', 'type': 'application/json', 'title': 'Processing results'}], 'assets': {'data': {'href': 's3://results/68046976-7dcb-11f0-90ac-2a20aea25780/68046976-7dcb-11f0-90ac-2a20aea25780/LC08_L2SP_044032_20231208_02_T1/otsu.tif', 'type': 'image/tiff; application=geotiff', 'raster:bands': [{'data_type': 'uint8', 'scale': 1.0, 'offset': 0.0, 'sampling': 'area', 'nodata': 0.0, 'statistics': {'mean': 1.0, 'minimum': 1, 'maximum': 1, 'stddev': 0.0, 'valid_percent': 60.46467784749034}, 'histogram': {'count': 11, 'min': 0.5, 'max': 1.5, 'buckets': [0, 0, 0, 0, 0, 481086, 0, 0, 0, 0]}}], 'storage:platform': 'eoap', 'storage:requester_pays': False, 'storage:tier': 'Standard', 'storage:region': 'us-east-1', 'storage:endpoint': 'http://eoap-zoo-project-localstack.eoap-zoo-project.svc.cluster.local:4566', 'roles': ['data', 'visual']}}, 'bbox': [-121.39922829056682, 39.82340258564599, -120.73977187420928, 40.482936393990066], 'stac_extensions': ['https://stac-extensions.github.io/projection/v1.1.0/schema.json', 'https://stac-extensions.github.io/raster/v1.1.0/schema.json'], 'collection': '68046976-7dcb-11f0-90ac-2a20aea25780'}, {'type': 'Feature', 'stac_version': '1.0.0', 'id': 'LC08_L2SP_043033_20231201_02_T1', 'properties': {'proj:epsg': 32610, 'proj:geometry': {'type': 'Polygon', 'coordinates': [[[636975.0, 4410555.0], [691605.0, 4410555.0], [691605.0, 4425015.0], [636975.0, 4425015.0], [636975.0, 4410555.0]]]}, 'proj:bbox': [636975.0, 4410555.0, 691605.0, 4425015.0], 'proj:shape': [482, 1821], 'proj:transform': [30.0, 0.0, 636975.0, 0.0, -30.0, 4425015.0, 0.0, 0.0, 1.0], 'datetime': '2023-12-01T18:39:41.392050Z'}, 'geometry': {'type': 'Polygon', 'coordinates': [[[-121.39922829056682, 39.83396419450036], [-120.76118304700903, 39.82340258564599], [-120.75694206934209, 39.95358698004168], [-121.3961944444915, 39.96419715990018], [-121.39922829056682, 39.83396419450036]]]}, 'links': [{'rel': 'collection', 'href': 's3://results/68046976-7dcb-11f0-90ac-2a20aea25780/68046976-7dcb-11f0-90ac-2a20aea25780/collection.json', 'type': 'application/json', 'title': 'Processing results'}, {'rel': 'root', 'href': 's3://results/68046976-7dcb-11f0-90ac-2a20aea25780/catalog.json', 'type': 'application/json'}, {'rel': 'self', 'href': 's3://results/68046976-7dcb-11f0-90ac-2a20aea25780/68046976-7dcb-11f0-90ac-2a20aea25780/LC08_L2SP_043033_20231201_02_T1/LC08_L2SP_043033_20231201_02_T1.json', 'type': 'application/json'}, {'rel': 'parent', 'href': 's3://results/68046976-7dcb-11f0-90ac-2a20aea25780/68046976-7dcb-11f0-90ac-2a20aea25780/collection.json', 'type': 'application/json', 'title': 'Processing results'}], 'assets': {'data': {'href': 's3://results/68046976-7dcb-11f0-90ac-2a20aea25780/68046976-7dcb-11f0-90ac-2a20aea25780/LC08_L2SP_043033_20231201_02_T1/otsu.tif', 'type': 'image/tiff; application=geotiff', 'raster:bands': [{'data_type': 'uint8', 'scale': 1.0, 'offset': 0.0, 'sampling': 'area', 'nodata': 0.0, 'statistics': {'mean': 1.0, 'minimum': 1, 'maximum': 1, 'stddev': 0.0, 'valid_percent': 12.31976677389706}, 'histogram': {'count': 11, 'min': 0.5, 'max': 1.5, 'buckets': [0, 0, 0, 0, 0, 34314, 0, 0, 0, 0]}}], 'storage:platform': 'eoap', 'storage:requester_pays': False, 'storage:tier': 'Standard', 'storage:region': 'us-east-1', 'storage:endpoint': 'http://eoap-zoo-project-localstack.eoap-zoo-project.svc.cluster.local:4566', 'roles': ['data', 'visual']}}, 'bbox': [-121.39922829056682, 39.82340258564599, -120.75694206934209, 39.96419715990018], 'stac_extensions': ['https://stac-extensions.github.io/projection/v1.1.0/schema.json', 'https://stac-extensions.github.io/raster/v1.1.0/schema.json'], 'collection': '68046976-7dcb-11f0-90ac-2a20aea25780'}], 'id': '68046976-7dcb-11f0-90ac-2a20aea25780'}\n</code></pre> <p>Creating ItemCollection </p> <pre><code>stac_items = ItemCollection.from_dict(stac_feature_collection).items\n</code></pre>"},{"location":"execute-monitor-process/#exploit-the-results","title":"Exploit the results","text":"<pre><code>for item in stac_items:\n\n    print(item.get_assets()[\"data\"].href)\n    print(json.dumps(item.get_assets()[\"data\"].to_dict(), sort_keys=True, indent=4))\n</code></pre> <pre><code>s3://results/68046976-7dcb-11f0-90ac-2a20aea25780/68046976-7dcb-11f0-90ac-2a20aea25780/LC08_L2SP_044032_20231208_02_T1/otsu.tif\n{\n    \"href\": \"s3://results/68046976-7dcb-11f0-90ac-2a20aea25780/68046976-7dcb-11f0-90ac-2a20aea25780/LC08_L2SP_044032_20231208_02_T1/otsu.tif\",\n    \"raster:bands\": [\n        {\n            \"data_type\": \"uint8\",\n            \"histogram\": {\n                \"buckets\": [\n                    0,\n                    0,\n                    0,\n                    0,\n                    0,\n                    481086,\n                    0,\n                    0,\n                    0,\n                    0\n                ],\n                \"count\": 11,\n                \"max\": 1.5,\n                \"min\": 0.5\n            },\n            \"nodata\": 0.0,\n            \"offset\": 0.0,\n            \"sampling\": \"area\",\n            \"scale\": 1.0,\n            \"statistics\": {\n                \"maximum\": 1,\n                \"mean\": 1.0,\n                \"minimum\": 1,\n                \"stddev\": 0.0,\n                \"valid_percent\": 60.46467784749034\n            }\n        }\n    ],\n    \"roles\": [\n        \"data\",\n        \"visual\"\n    ],\n    \"storage:endpoint\": \"http://eoap-zoo-project-localstack.eoap-zoo-project.svc.cluster.local:4566\",\n    \"storage:platform\": \"eoap\",\n    \"storage:region\": \"us-east-1\",\n    \"storage:requester_pays\": false,\n    \"storage:tier\": \"Standard\",\n    \"type\": \"image/tiff; application=geotiff\"\n}\ns3://results/68046976-7dcb-11f0-90ac-2a20aea25780/68046976-7dcb-11f0-90ac-2a20aea25780/LC08_L2SP_043033_20231201_02_T1/otsu.tif\n{\n    \"href\": \"s3://results/68046976-7dcb-11f0-90ac-2a20aea25780/68046976-7dcb-11f0-90ac-2a20aea25780/LC08_L2SP_043033_20231201_02_T1/otsu.tif\",\n    \"raster:bands\": [\n        {\n            \"data_type\": \"uint8\",\n            \"histogram\": {\n                \"buckets\": [\n                    0,\n                    0,\n                    0,\n                    0,\n                    0,\n                    34314,\n                    0,\n                    0,\n                    0,\n                    0\n                ],\n                \"count\": 11,\n                \"max\": 1.5,\n                \"min\": 0.5\n            },\n            \"nodata\": 0.0,\n            \"offset\": 0.0,\n            \"sampling\": \"area\",\n            \"scale\": 1.0,\n            \"statistics\": {\n                \"maximum\": 1,\n                \"mean\": 1.0,\n                \"minimum\": 1,\n                \"stddev\": 0.0,\n                \"valid_percent\": 12.31976677389706\n            }\n        }\n    ],\n    \"roles\": [\n        \"data\",\n        \"visual\"\n    ],\n    \"storage:endpoint\": \"http://eoap-zoo-project-localstack.eoap-zoo-project.svc.cluster.local:4566\",\n    \"storage:platform\": \"eoap\",\n    \"storage:region\": \"us-east-1\",\n    \"storage:requester_pays\": false,\n    \"storage:tier\": \"Standard\",\n    \"type\": \"image/tiff; application=geotiff\"\n}\n</code></pre> <p>In the cell below, the user opens a GeoTIFF file produced by the <code>water-bodies</code> job using <code>rasterio</code></p> <pre><code>region_name = os.environ.get(\"AWS_DEFAULT_REGION\")\nendpoint_url = os.environ.get(\"AWS_ENDPOINT_URL\", \"http://eoap-zoo-project-localstack:4566\")\naws_access_key_id = os.environ.get(\"AWS_ACCESS_KEY_ID\")\naws_secret_access_key = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\nregion_name, endpoint_url, aws_access_key_id, aws_secret_access_key\n\n# Extract image name using os.path.basename\nfull_path = item.get_assets()[\"data\"].href\nparsed_url = urlparse(full_path)\n\n# Extract the bucket name from the \"netloc\" part\nbucket_name = parsed_url.netloc\n\n# Extract the full path (excluding 's3://bucket_name')\nfull_path = parsed_url.path.lstrip(\"/\")\n\n# Extract image name using os.path.basename\nimage_name = os.path.basename(full_path)\n# Extract directory path using os.path.dirname\ndir_path = os.path.dirname(full_path)\nfs_opener = S3FS(\n        bucket_name=\"results\",\n        dir_path=dir_path,\n        aws_access_key_id=aws_access_key_id,\n        aws_secret_access_key=aws_secret_access_key,\n        endpoint_url=endpoint_url,\n        region=region_name,\n    )\n\nif fs_opener.region:\n    pass\nelse:\n    logger.error(\n        \"File system opener is not configurated properly to open file from s3 bucket\"\n    )\n\nwith rasterio.open(image_name, opener=fs_opener.open) as src:\n    profile = src.profile\n    print(profile)\n</code></pre> <pre><code>68046976-7dcb-11f0-90ac-2a20aea25780/68046976-7dcb-11f0-90ac-2a20aea25780/LC08_L2SP_044032_20231208_02_T1/otsu.tif\n{'driver': 'GTiff', 'dtype': 'uint8', 'nodata': 0.0, 'width': 1821, 'height': 2402, 'count': 1, 'crs': CRS.from_wkt('PROJCS[\"WGS 84 / UTM zone 10N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-123],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32610\"]]'), 'transform': Affine(30.0, 0.0, 636975.0,\n       0.0, -30.0, 4482615.0), 'blockxsize': 512, 'blockysize': 512, 'tiled': True, 'compress': 'lzw', 'interleave': 'band'}\n</code></pre> <p>Inspecting the job result using cli</p> <pre><code>!aws s3 ls s3://results/{job_id}/{job_id}/{os.path.basename(data[\"inputs\"][\"stac_items\"][0])}/\n</code></pre> <pre><code>2025-08-20 13:42:57       3447 LC08_L2SP_044032_20231208_02_T1.json\n2025-08-20 13:42:57     406547 otsu.tif\n</code></pre>"},{"location":"execution-scenario/","title":"Execution scenario","text":""},{"location":"execution-scenario/#user-personas","title":"User personas","text":"<p>The personas will help illustrate the workflow: Alice prepares and deploys the application, while Eric utilizes the deployed service to achieve his objectives.</p>"},{"location":"execution-scenario/#alice-eo-application-developer","title":"Alice \u2013 EO Application Developer","text":"<p>Alice is a developer specializing in Earth Observation (EO) applications. </p> <p>She creates geospatial processing solutions to analyze satellite data. For this tutorial, Alice has developed an application package for detecting water bodies using an algorithm based on the Normalized Difference Water Index (NDWI) and Otsu thresholding. </p> <p>She publishes this application package as a deployable process on an OGC API - Processes server.</p>"},{"location":"execution-scenario/#eric-data-scientist","title":"Eric \u2013 Data Scientist","text":"<p>Eric is a data scientist interested in using satellite imagery to monitor environmental changes, such as detecting water bodies. </p> <p>He discovers Alice\u2019s published application package and decides to use it by following the tutorial steps. </p> <p>Eric uses the OGC API - Processes interface to run Alice\u2019s application package on relevant datasets and retrieve results for analysis.</p>"},{"location":"execution-scenario/#user-scenarios","title":"User Scenarios","text":""},{"location":"execution-scenario/#alices-user-scenario","title":"Alice's User Scenario","text":"<p>Alice, an EO application developer, packages her water-bodies detection software as an EO Application Package. She follows these steps to create a deployable solution:</p> <ul> <li> <p>Prepare Container Images: She builds container images that include all execution dependencies for her software.</p> </li> <li> <p>Create CWL CommandLineTool Documents: Alice wraps her containerized command-line tools using CWL CommandLineTool documents.</p> </li> <li> <p>Orchestrate with a CWL Workflow: She organizes the CWL CommandLineTool documents into a workflow to execute the process.</p> </li> <li> <p>Test the Application Package: Alice verifies the application package through various execution scenarios.</p> </li> </ul> <p>This workflow allows Alice to share her EO Application Package for others like Eric to deploy on OGC API - Processes servers.</p> <p>Note: See https://eoap.github.io/mastering-app-package/ to learn about this scenario.</p>"},{"location":"execution-scenario/#erics-user-scenario","title":"Eric's User Scenario","text":"<p>Eric, a data scientist, wants to analyze satellite imagery to detect water bodies. He learns about Alice's published application package and follows these steps to achieve his goal:</p> <ul> <li> <p>Discover Alice\u2019s Application Package: Eric finds Alice's water-bodies detection application package in a repository or marketplace where it is shared.</p> </li> <li> <p>Deploy the Application: He deploys Alice\u2019s application package on an OGC API - Processes server, making the process available for execution.</p> </li> <li> <p>List Available Processes: Eric lists the processes on the server to confirm that the \"water-bodies\" process is now available.</p> </li> <li> <p>Check Process Details: He reviews the process's inputs and outputs to understand how to configure the execution.</p> </li> <li> <p>Execute the Process: Eric submits an execution request with the required parameters, such as area of interest and satellite data.</p> </li> <li> <p>Monitor Execution: He tracks the job's status to ensure it completes successfully.</p> </li> <li> <p>Access Results: Once the process finishes, Eric retrieves the outputs (e.g., a STAC catalog) for further analysis.</p> </li> </ul> <p>This workflow allows Eric to effectively utilize Alice\u2019s published application package for detecting water bodies.</p>"},{"location":"installation/","title":"Installing the ZOO-Project Helm chart on your platform","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<p>Before you begin, make sure you have the following tools installed and set up on your local environment:</p>"},{"location":"installation/#skaffold","title":"Skaffold","text":"<p>Skaffold is used to build, push, and deploy your application to Kubernetes. </p> <p>You can install it by following the instructions here.</p>"},{"location":"installation/#helm","title":"Helm","text":"<p>Helm is a package manager for Kubernetes, enabling you to manage Kubernetes applications easily. </p> <p>You can install it by following the steps here.</p>"},{"location":"installation/#dockerdesktop-required-for-apple-silicon","title":"Docker.Desktop (required for Apple silicon)","text":"<p>You can install it by following the steps here.</p> <p>From Docker.Desktop, enable Kubernetes in the Kubernetes settings pannel. Click on \"Apply &amp; restart\" button.</p>"},{"location":"installation/#minikube-not-required-for-apple-silicon","title":"Minikube (not required for Apple silicon)","text":"<p>Minikube runs a local Kubernetes cluster, ideal for development and testing. </p> <p>You can install it by following the guide here.</p> <p>Start your minikube instance with:</p> <pre><code>minikube start\n</code></pre>"},{"location":"installation/#optional-requirements","title":"Optional requirements","text":""},{"location":"installation/#kubectl","title":"Kubectl","text":"<p>Kubectl is a command-line tool for interacting with Kubernetes clusters. It allows you to manage and inspect cluster resources. While not strictly required, it's highly recommended for debugging and interacting with your Kubernetes environment.</p> <p>You can install it by following the instructions here.</p>"},{"location":"installation/#openlens","title":"OpenLens","text":"<p>OpenLens is a graphical user interface for managing and monitoring Kubernetes clusters. It provides a visual way to interact with resources. </p> <p>While it's optional, it can significantly improve your workflow. You can download it here.</p>"},{"location":"installation/#add-the-helm-repositories","title":"Add the helm repositories","text":"<pre><code>helm repo add localstack https://helm.localstack.cloud\nhelm repo add zoo-project https://zoo-project.github.io/charts/\n</code></pre>"},{"location":"installation/#checking-the-requirements","title":"Checking the requirements","text":"<p>After installing these tools, ensure they are available in your terminal by running the following commands:</p> <pre><code>skaffold version\nhelm version\n# The following command is not required to work on Apple silicon\nminikube version\n</code></pre> <p>If all commands return a version, you\u2019re good to go!</p>"},{"location":"installation/#deploying-the-workshop-environment","title":"Deploying the workshop environment","text":"<p>For the purpose of this workshop, we will use the following GitHub repository: dev-platform-eoap from the EOAP organization.</p> <p>Start the workshop environment.</p> <pre><code>git clone https://github.com/eoap/dev-platform-eoap.git\ncd dev-platform-eoap/ogc-api-processes-with-zoo/\nskaffold dev -p standard\n# Apple user must use the additional options below\ndocker pull zooproject/zoo-project:dru-2b3610cbb1198accadc14b6dead93ae29bd927fd --platform linux/amd64\nskaffold dev -p macos --platform linux/amd64 --enable-platform-node-affinity=true\n</code></pre> <p>After some time you will see something like the following indicating that everything is in place.</p> <pre><code>No tags generated\nStarting deploy...\nHelm release zoo-project-dru not installed. Installing...\nNAME: zoo-project-dru\nLAST DEPLOYED: Mon Mar 10 18:46:58 2025\nNAMESPACE: eoap-zoo-project\nSTATUS: deployed\nREVISION: 1\nNOTES:\n1. Get the application URL by running these commands:\n  export POD_NAME=$(kubectl get pods --namespace eoap-zoo-project -l \"app.kubernetes.io/name=zoo-project-dru,app.kubernetes.io/instance=zoo-project-dru\" -o jsonpath=\"{.items[0].metadata.name}\")\n  export CONTAINER_PORT=$(kubectl get pod --namespace eoap-zoo-project $POD_NAME -o jsonpath=\"{.spec.containers[0].ports[0].containerPort}\")\n  echo \"Visit http://127.0.0.1:8080 to use your application\"\n  kubectl --namespace eoap-zoo-project port-forward $POD_NAME 8080:$CONTAINER_PORT\nHelm release eoap-zoo-project-coder not installed. Installing...\nNAME: eoap-zoo-project-coder\nLAST DEPLOYED: Mon Mar 10 18:47:00 2025\nNAMESPACE: eoap-zoo-project\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nHelm release eoap-zoo-project-localstack not installed. Installing...\nNAME: eoap-zoo-project-localstack\nLAST DEPLOYED: Mon Mar 10 18:47:01 2025\nNAMESPACE: eoap-zoo-project\nSTATUS: deployed\nREVISION: 1\nNOTES:\n1. Get the application URL by running these commands:\n  export POD_NAME=$(kubectl get pods --namespace \"eoap-zoo-project\" -l \"app.kubernetes.io/name=localstack,app.kubernetes.io/instance=eoap-zoo-project-localstack\" -o jsonpath=\"{.items[0].metadata.name}\")\n  export CONTAINER_PORT=$(kubectl get pod --namespace \"eoap-zoo-project\" $POD_NAME -o jsonpath=\"{.spec.containers[0].ports[0].containerPort}\")\n  echo \"visit http://127.0.0.1:8080 to use your application\"\n  kubectl --namespace \"eoap-zoo-project\" port-forward $POD_NAME 8080:$CONTAINER_PORT\nWaiting for deployments to stabilize...\n - eoap-zoo-project:deployment/zoo-project-dru-kubeproxy is ready. [6/7 deployment(s) still pending]\nI0310 18:47:06.018653 2854542 request.go:697] Waited for 1.124380065s due to client-side throttling, not priority and fairness, request: GET:https://127.0.0.1:36205/api/v1/namespaces/eoap-zoo-project/events?fieldSelector=involvedObject.name%3Dcode-server-deployment-d94b68f99-p5qdv%2CinvolvedObject.namespace%3Deoap-zoo-project%2CinvolvedObject.kind%3DPod%2CinvolvedObject.uid%3D28193f9d-458c-476d-af26-c4bf45b0f9e4\n - eoap-zoo-project:deployment/code-server-deployment: FailedToRetrieveImagePullSecret: Unable to retrieve some image pull secrets (kaniko-secret); attempting to pull the image may not succeed.\n    - eoap-zoo-project:pod/code-server-deployment-d94b68f99-p5qdv: FailedToRetrieveImagePullSecret: Unable to retrieve some image pull secrets (kaniko-secret); attempting to pull the image may not succeed.\n      &gt; [code-server-deployment-d94b68f99-p5qdv init-file-on-volume] Cloning into 'ogc-api-processes-with-zoo'...\n      &gt; [code-server-deployment-d94b68f99-p5qdv init-file-on-volume] [2025-03-10T17:47:04.843Z] info  Wrote default config file to /workspace/.config/code-server/config.yaml\n - eoap-zoo-project:deployment/eoap-zoo-project-localstack: waiting for rollout to finish: 0 of 1 updated replicas are available...\n - eoap-zoo-project:deployment/zoo-project-dru-zoofpm: waiting for init container init-wait-for-dependencies-zoofpm to complete\n    - eoap-zoo-project:pod/zoo-project-dru-zoofpm-5d77cbb77f-8t2lw: waiting for init container init-wait-for-dependencies-zoofpm to complete\n      &gt; [zoo-project-dru-zoofpm-5d77cbb77f-8t2lw init-wait-for-dependencies-zoofpm] nc: bad address 'zoo-project-dru-rabbitmq:5672'\n      &gt; [zoo-project-dru-zoofpm-5d77cbb77f-8t2lw init-wait-for-dependencies-zoofpm] zoo-project-dru-rabbitmq:5672 is unavailable - sleeping\n      &gt; [zoo-project-dru-zoofpm-5d77cbb77f-8t2lw init-wait-for-dependencies-zoofpm] nc: bad address 'zoo-project-dru-rabbitmq:5672'\n      &gt; [zoo-project-dru-zoofpm-5d77cbb77f-8t2lw init-wait-for-dependencies-zoofpm] zoo-project-dru-rabbitmq:5672 is unavailable - sleeping\n - eoap-zoo-project:deployment/zoo-project-dru-zookernel: waiting for init container init-wait-for-dependencies-zookernel to complete\n    - eoap-zoo-project:pod/zoo-project-dru-zookernel-8675b6d96f-xfjhp: waiting for init container init-wait-for-dependencies-zookernel to complete\n      &gt; [zoo-project-dru-zookernel-8675b6d96f-xfjhp init-wait-for-dependencies-zookernel] nc: bad address 'zoo-project-dru-rabbitmq:5672'\n      &gt; [zoo-project-dru-zookernel-8675b6d96f-xfjhp init-wait-for-dependencies-zookernel] zoo-project-dru-rabbitmq:5672 is unavailable - sleeping\n      &gt; [zoo-project-dru-zookernel-8675b6d96f-xfjhp init-wait-for-dependencies-zookernel] nc: bad address 'zoo-project-dru-rabbitmq:5672'\n      &gt; [zoo-project-dru-zookernel-8675b6d96f-xfjhp init-wait-for-dependencies-zookernel] zoo-project-dru-rabbitmq:5672 is unavailable - sleeping\n - eoap-zoo-project:statefulset/zoo-project-dru-postgresql: Waiting for 1 pods to be ready...\n - eoap-zoo-project:statefulset/zoo-project-dru-rabbitmq: Waiting for 1 pods to be ready...\n - eoap-zoo-project:statefulset/zoo-project-dru-postgresql is ready. [5/7 deployment(s) still pending]\n - eoap-zoo-project:deployment/eoap-zoo-project-localstack is ready. [4/7 deployment(s) still pending]\n - eoap-zoo-project:statefulset/zoo-project-dru-rabbitmq is ready. [3/7 deployment(s) still pending]\n - eoap-zoo-project:deployment/zoo-project-dru-zoofpm is ready. [2/7 deployment(s) still pending]\n - eoap-zoo-project:deployment/zoo-project-dru-zookernel is ready. [1/7 deployment(s) still pending]\n - eoap-zoo-project:deployment/code-server-deployment is ready.\nDeployments stabilized in 40.089 seconds\nPort forwarding service/zoo-project-dru-service in namespace eoap-zoo-project, remote port 80 -&gt; http://localhost:8080\nPort forwarding service/code-server-service in namespace eoap-zoo-project, remote port 8080 -&gt; http://localhost:8000\nNo artifacts found to watch\nPress Ctrl+C to exit\nWatching for changes...\n</code></pre>"},{"location":"installation/#accessing-the-ogc-api-processes-engine","title":"Accessing the OGC API Processes Engine","text":"<p>From there, you can access the EOEPCA Processing - OGC API Processes Engine using the following URL: http://localhost:8080.</p> <p>In addition, there is a Code Server available on http://localhost:8000 where you can find the notebooks.</p>"},{"location":"list-processes/","title":"List the deployed processes","text":"<p>To list the deployed processes, OGC API Processes API uses the resource highlighted in the table below:</p> Resource Path Purpose Part Landing page <code>/</code> Top-level resource serving as an entry point. Part 1 Conformance declaration <code>/conformance</code> Information about the functionality supported by the server. Part 1 API Definition <code>/api</code> Metadata about the API itself. Part 1 Process list <code>/processes</code> Lists available processes with identifiers and links to descriptions. Part 1 Process description <code>/processes/{processID}</code> Retrieves detailed information about a specific process. Part 1 Process execution <code>/processes/{processID}/execution</code> (POST) Executes a process, creating a job. Part 1 Deploy Process <code>/processes</code> (POST) Deploys a new process on the server. Part 2 Replace Process <code>/processes/{processID}</code> (PUT) Replaces an existing process with a new version. Part 2 Undeploy Process <code>/processes/{processID}</code> (DELETE) Removes an existing process from the server. Part 2 EO Application Package <code>/processes/{processID}/package</code> Get the EOAP associated with a deployed process. Part 2 Job status info <code>/jobs/{jobID}</code> Retrieves the current status of a job. Part 1 Job results <code>/jobs/{jobID}/results</code> Retrieves the results of a job. Part 1 Job list <code>/jobs</code> Retrieves a list of submitted jobs. Part 1 Job deletion <code>/jobs/{jobID}</code> (DELETE) Cancels and deletes a job. Part 1 <pre><code>import requests\nimport json\n\nnamespace = \"acme\"\n\nogc_api_endpoint = f\"http://zoo-project-dru-service/{namespace}/ogc-api\"\n\nresponse = requests.get(f\"{ogc_api_endpoint}/processes\")\n</code></pre> <p>In the cell below, the user will explore the number of deployed processes available on the OGC API endpoint, along with their associated metadata.</p> <pre><code># Check if the request was successful\nif response.status_code == 200:\n    # Parse the JSON response\n    processes = response.json()\n\n    # Display the number of processes available\n    print(f\"Number of available processes: {processes.get('numberTotal', 0)}\")\n\n    # Iterate through each process and print its details\n    for process in processes.get(\"processes\", []):\n        if process.get(\"id\") in [\"echo\"]:\n            print(f\"\\nProcess ID: {process.get('id')} - skipped (ZOO Project uses this process for conformance testing)\")\n            continue\n        print(f\"\\nProcess ID: {process.get('id')}\")\n        print(f\"Title: {process.get('title')}\")\n        print(f\"Description: {process.get('description')}\")\n        print(f\"Version: {process.get('version')}\")\n        print(f\"Mutable: {process.get('mutable')}\")\n        print(f\"Job Control Options: {process.get('jobControlOptions')}\")\n        print(f\"Output Transmission: {process.get('outputTransmission')}\")\n\n        # Print available links for the process\n        for link in process.get(\"links\", []):\n            print(f\"Link: {link.get('title')} - {link.get('href')}\")\nelse:\n    print(f\"Failed to list processes. Status code: {response.status_code}\")\n</code></pre> <pre><code>Number of available processes: 2\n\nProcess ID: echo - skipped (ZOO Project uses this process for conformance testing)\n\nProcess ID: water-bodies\nTitle: Water bodies detection based on NDWI and otsu threshold\nDescription: Water bodies detection based on NDWI and otsu threshold applied to Sentinel-2 COG STAC items\nVersion: 1.0.0\nMutable: True\nJob Control Options: ['async-execute', 'dismiss']\nOutput Transmission: ['value', 'reference']\nLink: Process Description - http://localhost:8080/acme/ogc-api/processes/water-bodies\n</code></pre>"},{"location":"list-processes/#explanation","title":"Explanation","text":"<p>Fetching Available Processes:</p> <p>The <code>/processes</code> endpoint is used to list all processes.</p> <p>The response is parsed to extract information about each process.</p> <p>Displaying Process Details:</p> <p>For each process, the script displays the id, title, description, version, whether the process is mutable, the jobControlOptions, and outputTransmission options.</p> <p>Links related to the process (e.g., process description or execution endpoint) are also displayed.</p> <p>Understanding the Output</p> <p>Process ID: Unique identifier for the process. Title and Description: Provide information about the process functionality. Version: Indicates the process version. Mutable: If True, the process can be modified or redeployed. Job Control Options: Specifies how the process can be executed (e.g., synchronously, asynchronously, or dismissed). Output Transmission: Indicates the methods available for retrieving process results. Links: URLs to access more information about the process, such as its description or execution endpoint.</p> <p>Next Steps</p> <p>Once you have listed the processes, you can proceed with:</p> <ul> <li>Viewing process details using the links provided in the output.</li> <li>Deploying new processes if needed.</li> <li>Executing available processes to perform geospatial tasks.</li> </ul> <p>This tutorial provides a basic way to list processes and gather information, forming the foundation for more complex interactions with the ZOO-Project's OGC API.</p>"},{"location":"app/water-bodies-detection/","title":"Water bodies detection","text":"<p>This learning module re-uses an Application Package asset that is described in the Mastering Earth Observation Application Packaging with CWL module.</p> <p>In the context of the module, the Application Package is built and released by a Continuous Integration process running in GitHub and producing the releases found under https://github.com/eoap/mastering-app-package/releases/.</p> <p>The paragraphs below provide an overview of the application packaged as a OGC Earth Observation Application Package.  </p>"},{"location":"app/water-bodies-detection/#application-overview","title":"Application overview","text":"<p>This application takes as input Copernicus Sentinel-2 or USSG Landsat-9 data and detects water bodies by applying the Otsu thresholding technique on the Normalized Difference Water Index (NDWI).</p> <p>The NDWI is calculated with: </p> \\[ NDWI = { (green - nir) \\over (green + nir) }  \\] <p>Typically, NDWI values of water bodies are larger than 0.2 and built-up features have positive values between 0 and 0.2.</p> <p>Vegetation has much smaller NDWI values, which results in distinguishing vegetation from water bodies easier. </p> <p>The NDWI values correspond to the following ranges:</p> Range Description 0,2 - 1 Water surface 0.0 - 0,2 Flooding, humidity -0,3 - 0.0 Moderate drought, non-aqueous surfaces -1 - -0.3 Drought, non-aqueous surfaces <p>To ease the determination of the water surface/non water surface, the Ostu thresholding technique is used. </p> <p>In the simplest form, the Otsu algorithm returns a single intensity threshold that separate pixels into two classes, foreground and background. This threshold is determined by minimizing intra-class intensity variance, or equivalently, by maximizing inter-class variance:</p> <p></p>"},{"location":"app/water-bodies-detection/#application-details","title":"Application details","text":"<p>The application is a Python command line tool that takes a Sentinel-2 STAC item reference applies the crop over the area of interest for the radiometric bands green and NIR, the normalized difference, the Ostu threshold and finally creates a STAC catalog and items for the generated results.</p> <p>This scenario is depicted below:</p> graph TB subgraph Process STAC item   A[STAC Item] -- STAC Item URL --&gt; B   A[STAC Item] -- STAC Item URL --&gt; C   A[STAC Item] -- STAC Item URL --&gt; F subgraph loop on bands   B[\"crop(green)\"];   C[\"crop(nir)\"]; end   B[\"crop(green)\"] -- crop_green.tif --&gt; D[Normalized difference];   C[\"crop(nir)\"] -- crop_nir.tif --&gt; D[Normalized difference];   D -- norm_diff.tif --&gt; E[Otsu threshold] end   E -- otsu.tif --&gt; F[Create STAC Catalog]   F -- \"catalog.json/item.json/asset otsu.tif\" --&gt; G[(storage)]"},{"location":"app/water-bodies-detection/#application-package","title":"Application Package","text":"<p>The user packages the application as an Application Package to include a workflow that reads a Sentinel-2 STAC item references launches Python command line tool to detect the water bodies:</p> <p></p>"},{"location":"app/water-bodies-detection/#dataset","title":"Dataset","text":"<p>The development and test dataset is made of two Sentinel-2 acquisitions:</p> Acquisitions Mission Sentinel-2 Sentinel-2 Date 2022-05-24 2021-07-13 URL S2B_10TFK_20210713_0_L2A S2A_10TFK_20220524_0_L2A Quicklook <p>The execution scenario using the OGC API Processes processes several acquisitions, including the two above. </p>"},{"location":"containers/ogc_api_processes_client/","title":"OGC API Process Client","text":""},{"location":"containers/ogc_api_processes_client/#goal","title":"Goal","text":"<p>Create a container and run the <code>ogc-api-processes-client</code> step in the container image. This container will interact with the a deployrd process (e.g. water-bodies) on the OGC API endpint, submit a job with the recived inputs, monitor the job for any upcoming event(e.g running, successful, failed), and finally create STAC ItemCollection with assets pointing to the results. </p>"},{"location":"containers/ogc_api_processes_client/#lab","title":"Lab","text":"<p>This step has a dedicated lab available at execute-monitor-process.md. But it is very important to run 01-Deploy-an-application-package.ipynb before proceeding with job execution step.</p>"},{"location":"containers/ogc_api_processes_client/#container","title":"Container","text":"<p>This <code>ogc-api-processes-client</code> has its own recipe to build the container image. The recipe is provided in the cell below:</p> ogc-api-processes-client/Dockerfile<pre><code># Stage 1: Build stage\nFROM rockylinux:9.3-minimal AS build\n\n# Install necessary build tools\nRUN microdnf install -y curl tar &amp;&amp; \\\n    microdnf clean all\n\n# Download the hatch tar.gz file from GitHub\nRUN curl -L https://github.com/pypa/hatch/releases/latest/download/hatch-x86_64-unknown-linux-gnu.tar.gz -o /tmp/hatch-x86_64-unknown-linux-gnu.tar.gz\n\n# Extract the hatch binary\nRUN tar -xzf /tmp/hatch-x86_64-unknown-linux-gnu.tar.gz -C /tmp/\n\n# Stage 2: Final stage\nFROM rockylinux:9\n\n# Install runtime dependencies\nRUN dnf install -y --nodocs which expat &amp;&amp; \\\n    dnf clean all\n\n# Set up a default user and home directory\nENV HOME=/home/ogc\n\n# Create a user with UID 1001, group root, and a home directory\nRUN useradd -u 1001 -r -g 0 -m -d ${HOME} -s /sbin/nologin \\\n        -c \"Default ogc User\" ogc &amp;&amp; \\\n    mkdir -p /code &amp;&amp; \\\n    mkdir -p /prod &amp;&amp; \\\n    chown -R 1001:0 /code &amp;&amp; \\\n    chmod g+rwx ${HOME} /code\n\n# Copy the hatch binary from the build stage\nCOPY --from=build /tmp/hatch /usr/bin/hatch\n\n# Ensure the hatch binary is executable\nRUN chmod +x /usr/bin/hatch\n\n# Install runtime dependencies\nRUN dnf install -y which jq git &amp;&amp; \\\n    dnf clean all\n\n\n# Copy the application files into the /code directory\nCOPY --chown=1001:0 . /code\n\nARG STARS_VERSION\n\nRUN if [[ -n \"$STARS_VERSION\" ]] ; then dnf install -y https://github.com/Terradue/Stars/releases/download/$STARS_VERSION/Stars.$STARS_VERSION.linux-x64.rpm; Stars --help;  fi \n\n# Switch to the non-root user\nUSER ogc\nWORKDIR /code\n\n# Set up virtual environment paths\nENV VIRTUAL_ENV=/code/envs/ogc\nENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\n\n# Prune any existing environments and create a new production environment\nRUN hatch env prune &amp;&amp; \\\n    hatch env create prod &amp;&amp; \\\n    hatch run prod:ogc-api-processes-client --help &amp;&amp; \\\n    chmod +rx -R /code/envs/ogc &amp;&amp; \\\n    chmod +rx -R /home/ogc &amp;&amp; \\\n    rm -fr /code/.git /code/.pytest_cache\n\n\nWORKDIR /code\n\n# Set the default command to run when the container starts\nCMD [\"ogc-api-processes-client\"]\n</code></pre> <p>Build the container image with:</p> terminal<pre><code>#!/bin/bash\nexport WORKSPACE=$PWD\ndocker_tag=$(yq eval '\n  .\"$graph\"[]\n  | select(.id == \"ogc-api-processes-client\")\n  | .requirements[]\n  | select(.class == \"DockerRequirement\")\n  | .dockerPull\n' cwl-workflows/eoap-api-cli.cwl)\n\necho $docker_tag\ndocker build -t $docker_tag $WORKSPACE/containers/ogc-api-processes-client\n</code></pre>"},{"location":"containers/ogc_api_processes_client/#how-to-run-a-step-in-a-container","title":"How to run a step in a container","text":"<p>We'll use <code>podman</code> container engine (<code>docker</code> is also fine).</p> <p>Before running the container using <code>podman</code> it is very important to deploy the application package such as <code>water-bodies</code> on the OGC endpoint. The deployment of water-bodies application package is explained in 01-Deploy-an-application-package.ipynb. Once the deployment was successful, the command to run the <code>ogc-api-processes-client</code> step in the container is:</p> <pre><code>docker_tag=$(yq eval '\n  .\"$graph\"[]\n  | select(.id == \"ogc-api-processes-client\")\n  | .requirements[]\n  | select(.class == \"DockerRequirement\")\n  | .dockerPull\n' cwl-workflows/eoap-api-cli.cwl)\n\npodman \\\n    run \\\n    -i \\\n    --userns=keep-id \\\n    --mount=type=bind,source=/workspace/ogc-api-processes-with-zoo/runs,target=/runs \\\n    --workdir=/runs \\\n    --read-only=true \\\n    --user=1001:100 \\\n    --rm \\\n    --env=TMPDIR=/tmp \\\n    --env=HOME=/runs \\\n    $docker_tag \\\n    ogc-api-processes-client \\\n    --api-endpoint \\\n    http://zoo-project-dru-service/acme/ogc-api/ \\\n    --process-id \\\n    water-bodies \\\n    --execute-request \\\n    containers/ogc-api-processes-client/execute_request.json \\\n    --output \\\n    feature-collection.json\n</code></pre> <p>Let's break down what this command does:</p> <ul> <li><code>podman run</code>: This is the command to run a container.</li> <li><code>-i</code>: This flag makes the container interactive, allowing you to interact with it via the terminal.</li> <li><code>--userns=keep-id</code>: It instructs <code>podman</code> to keep the user namespace ID. <code>--mount=type=bind,source=/workspace/ogc-api-processes-with-zoo/runs,target=/runs</code>: This option mounts a directory from the host system to the container. In this case, it mounts the <code>/workspace/ogc-api-processes-with-zoo/runs</code> directory on the host to the <code>/runs</code> directory inside the container.</li> <li><code>--workdir=/runs</code>: Sets the working directory inside the container to <code>/runs</code>.</li> <li><code>--read-only=true</code>: Makes the file system inside the container read-only, meaning you can't write or modify files inside the container.</li> <li><code>--user=1001:100</code>: Specifies the user and group IDs to be used within the container.</li> <li><code>--rm</code>: This flag tells podman to remove the container after it has finished running.</li> <li><code>--env=HOME=/runs</code>: Sets the <code>HOME</code> environment variable inside the container to <code>/runs</code>.</li> <li><code>$docker_tag</code>: This is the name of the container image that you were built earlier and want to run.</li> <li><code>ogc-api-processes-client</code>: This is the command to run inside the container. It runs a Python module named \"ogc-api-processes-client\"</li> <li><code>--api-endpoint \"http://zoo-project-dru-service/acme/ogc-api/\"</code>: This provides command-line arguments to the Python module. It specifies the address to the OGC API endpoint where the service is running.</li> <li><code>--process-id</code>: Specifies the id of process we deployed (e.g. <code>water-bodies</code>) in 01-Deploy-an-application-package.ipynb.</li> <li><code>--execute-request</code>: This input point to the JSON file containing the information of two sentinel-2/landsat products from planetarycomputer are going to pass to the <code>water-bodies</code> application pacakge. An expample of this JSON file is mentioned below:</li> </ul> execute_request.json<pre><code>{\n    \"inputs\": {\n        \"stac_items\": [\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/landsat-c2-l2/items/LC08_L2SP_044032_20231208_02_T1\",\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/landsat-c2-l2/items/LC08_L2SP_043033_20231201_02_T1\"\n        ],\n        \"aoi\": \"-121.399,39.834,-120.74,40.472\",\n        \"epsg\": \"EPSG:4326\",\n        \"bands\": [\n            \"green\",\n            \"nir08\"\n        ]\n    }\n}\n</code></pre> <ul> <li><code>--output</code>: This input would pass the JSON file name containing the result of wate-bodies detection in STAC ItemCollection format</li> </ul>"},{"location":"containers/ogc_api_processes_client/#expected-outcome","title":"Expected outcome","text":"<p>The folder <code>/workspace/ogc-api-processes-with-zoo/runs</code> contains: </p> <pre><code>(base) jovyan@coder-mrossi:~/runs$ tree .\n.\n\u2514\u2500\u2500 feature-collection.json\n\n0 directories, 1 file\n</code></pre>"},{"location":"containers/scope/","title":"Scope","text":"<p>When developers package and EO, they are in fact packaging their own software, written in a specific programming language, as a containerized application (or a set of containerized applications), to be described as an EO Application Package using the Common Workflow Language as described in the OGC proposed best practices.</p> <p>To achieve this, developers follow the steps described below.</p> <ul> <li>Prepare one or more container images containing the execution dependencies of the software.</li> <li>Prepare the CWL CommandLineTool document(s) wrapping the command line tool available container(s).</li> <li>Prepare the CWL Workflow orchestrating CWL CommandLineTool document(s) wrapping the command line tool available container(s).</li> <li>Test the application package in one or more execution scenarios.</li> </ul> <p>This section shows how to do the step:</p> <ul> <li>Prepare one or more container images containing the execution dependencies of the software.</li> </ul>"},{"location":"cwl-cli/ogc-api-processes-client/","title":"OGC API Process Client CommandLineTool","text":""},{"location":"cwl-cli/ogc-api-processes-client/#goal","title":"Goal","text":"<p>Wrap the <code>ogc-api-processes-client</code> step as a Common Workflow Language CommandLineTool and execute it with a CWL runner. Indeed, it will interact with the a deployrd process (e.g. <code>water-bodies</code>) on the OGC API endpint, submit a job with the recived inputs, monitor the job for any upcoming event(e.g running, successful, failed), and finally create STAC ItemCollection with assets pointing to the results. </p>"},{"location":"cwl-cli/ogc-api-processes-client/#how-to-wrap-a-step-as-a-cwl-commandlinetool","title":"How to wrap a step as a CWL CommandLineTool","text":"<p>The CWL document below shows the <code>ogc-api-processes-client</code> step wrapped as a CWL CommandLineTool:</p> ogc-api-processes-client-cli.cwl<pre><code>cwlVersion: v1.2\n$graph:\n- class: CommandLineTool\n  id: ogc-api-processes-client\n  label: geo API - Processes\n\n  requirements:\n  - class: InlineJavascriptRequirement\n  - class: DockerRequirement\n    dockerPull:  localhost/ogc \n  - class: SchemaDefRequirement\n    types:\n    - $import: https://raw.githubusercontent.com/eoap/schemas/main/string_format.yaml\n    - $import: https://raw.githubusercontent.com/eoap/schemas/main/geojson.yaml\n    - $import: |-\n        https://raw.githubusercontent.com/eoap/schemas/main/experimental/api-endpoint.yaml\n    - $import: https://raw.githubusercontent.com/eoap/schemas/main/experimental/process.yaml\n  inputs:\n    api_endpoint:\n      label: OGC API endpoint\n      doc: OGC API endpoint for Landsat-9 data\n      type: |-\n        https://raw.githubusercontent.com/eoap/schemas/main/experimental/api-endpoint.yaml#APIEndpoint\n    execute_request:\n      label: OGC API Processes settings\n      doc: OGC API Processes settings for Landsat-9 data\n      type: File\n    process_id:\n      label: Process ID\n      doc: Process ID for the OGC API Processes\n      type: Any\n\n  outputs:\n    process_output:\n      type: File\n      outputBinding:\n        glob: feature-collection.json\n  baseCommand: [\"ogc-api-processes-client\"]\n  arguments:\n    - --api-endpoint\n    - $(inputs.api_endpoint.url.value)\n    - --process-id\n    - $(inputs.process_id)\n    - --execute-request \n    - $(inputs.execute_request.path)\n    - --output\n    - feature-collection.json\n</code></pre> <p>Let's break down the key components of this CWL document:</p> <ul> <li> <p><code>cwlVersion: v1.2</code>    Specifies that this CWL document uses version 1.2 of the CWL specification.</p> </li> <li> <p><code>class: CommandLineTool</code>    Indicates that this CWL document defines a command-line tool.</p> </li> <li> <p><code>id</code> and <code>label</code></p> </li> <li> <p><code>id: ogc-api-processes-client</code> \u2014 unique identifier for this tool.</p> </li> <li> <p><code>label: Geo API - Processes</code> \u2014 human-readable name.</p> </li> <li> <p><code>requirements</code>    Defines the execution environment and runtime features:</p> </li> <li> <p><code>InlineJavascriptRequirement</code> \u2014 Allows the use of inline JavaScript expressions in the tool like <code>$(inputs.xyz)</code> in arguments.</p> </li> <li><code>DockerRequirement</code> \u2014 specifies the Docker container image refrence for execution.</li> <li> <p><code>SchemaDefRequirement</code> \u2014 imports custome schemas for input validation:</p> <ul> <li><code>string_format.yaml</code></li> <li><code>geojson.yaml</code></li> <li><code>api-endpoint.yaml</code></li> <li><code>process.yaml</code></li> </ul> </li> <li> <p><code>inputs</code>    The tool expects three inputs:</p> </li> <li> <p><code>api_endpoint</code>: the OGC API URL (validated against a schema).</p> </li> <li> <p><code>execute_request</code>: JSON file with process parameters. An expample of this JSON file is mentioned below:</p> <pre><code>```\n{\n    \"inputs\": {\n        \"stac_items\": [\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/landsat-c2-l2/items/LC08_L2SP_044032_20231208_02_T1\",\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/landsat-c2-l2/items/LC08_L2SP_043033_20231201_02_T1\"\n        ],\n        \"aoi\": \"-121.399,39.834,-120.74,40.472\",\n        \"epsg\": \"EPSG:4326\",\n        \"bands\": [\n            \"green\",\n            \"nir08\"\n        ]\n    }\n}\n```\n</code></pre> <ul> <li><code>process_id</code>: identifier of the OGC process to run.</li> </ul> </li> <li> <p><code>outputs</code>    Defines what the tool produces:</p> </li> <li> <p><code>process_output</code>: a file called <code>feature-collection.json</code>.</p> </li> <li> <p><code>baseCommand</code> and <code>arguments</code></p> </li> <li> <p><code>baseCommand: [\"ogc-api-processes-client\"]</code> which is the command executed inside Docker.</p> </li> <li> <p><code>arguments</code> \u2014 maps CWL inputs to command-line flags:</p> <ul> <li><code>--api-endpoint</code> \u2192 <code>$(inputs.api_endpoint.url.value)</code></li> <li><code>--process-id</code> \u2192 <code>$(inputs.process_id)</code></li> <li><code>--execute-request</code> \u2192 <code>$(inputs.execute_request.path)</code></li> <li><code>--output</code> \u2192 <code>feature-collection.json</code></li> </ul> </li> </ul>"},{"location":"cwl-cli/prepare-execute/","title":"Prepare Execute Request CommandLineTool","text":""},{"location":"cwl-cli/prepare-execute/#goal","title":"Goal","text":"<p>Wrap the <code>prepare-execute-request</code> step as a Common Workflow Language CommandLineTool and execute it with a CWL runner. Indeed, it prepare the execute request JSON file for OGC API Processes based on search results </p>"},{"location":"cwl-cli/prepare-execute/#how-to-wrap-a-step-as-a-cwl-commandlinetool","title":"How to wrap a step as a CWL CommandLineTool","text":"<p>The CWL document below shows the <code>prepare-execute-request</code> step wrapped as a CWL CommandLineTool:</p> prepare-execute-request-cli.cwl<pre><code>cwlVersion: v1.2\n$graph:\n- class: CommandLineTool\n  id: prepare-execute-request\n  label: Prepare Execute Request\n  doc: Prepare the execute request for OGC API Processes based on search results \n\n  baseCommand: [\"/bin/bash\", \"run.sh\"]\n  arguments: []\n\n  requirements:\n  - class: InlineJavascriptRequirement\n  - class: SchemaDefRequirement\n    types:\n    - $import: https://raw.githubusercontent.com/eoap/schemas/main/string_format.yaml\n    - $import: https://raw.githubusercontent.com/eoap/schemas/main/geojson.yaml\n    - $import: |-\n        https://raw.githubusercontent.com/eoap/schemas/main/experimental/api-endpoint.yaml\n    - $import: https://raw.githubusercontent.com/eoap/schemas/main/experimental/process.yaml\n  - class: NetworkAccess\n    networkAccess: true\n  - class: InitialWorkDirRequirement\n    listing:\n    - entryname: input_execute_request.json\n      entry: |-\n        ${ return JSON.stringify(inputs.in_execute_request, null, 2); }\n    - entryname: process_id.json\n      entry: |-\n        ${ return JSON.stringify(inputs.in_execute_request.process_id, null, 2); }\n    - entryname: run.sh\n      entry: |-\n        #!/usr/bin/env bash\n        set -x\n        set -euo pipefail\n\n\n        jq '[.features[].links[] | select(.rel==\"self\") | .href]' \"$(inputs.search_results.path)\" &gt; stac_items.json\n\n        jq --argjson stac_items \"`cat stac_items.json`\" \\\n          'del(.process_id) | .inputs.stac_items = $stac_items' \\\n          input_execute_request.json &gt; execute_request.json\n\n        cat execute_request.json | jq .\n\n  inputs:\n    in_execute_request:\n      label: OGC API Processes settings\n      doc: OGC API Processes settings for Landsat-9 data\n      type: |-\n        https://raw.githubusercontent.com/eoap/schemas/main/experimental/process.yaml#OGCExecuteProcessSettings\n\n    search_results:\n      label: Search Results\n      doc: Search results from the discovery step\n      type: File\n\n  outputs:\n    execute_request:\n      type: File\n      outputBinding:\n        glob: execute_request.json\n    process_id:\n      type: Any\n      outputBinding:\n        glob: process_id.json\n        loadContents: true\n        outputEval: ${ return JSON.parse(self[0].contents); }\n</code></pre> <p>Let's break down the key components of this CWL document:</p> <ul> <li> <p><code>cwlVersion: v1.2</code>: Specifies the version of the CWL specification that this document follows.</p> </li> <li> <p><code>class: CommandLineTool</code>: Indicates that this CWL document defines a command-line tool.</p> </li> <li> <p><code>id: prepare-execute-request</code>: Provides a unique identifier for this tool, which can be referenced in workflows.</p> </li> <li> <p><code>arguments</code>: This section is empty, meaning there are no additional command-line arguments specified here. The tool receives its arguments via the input parameters.</p> </li> <li> <p><code>baseCommand</code>: Defines the base command to be executed. In this case, it's running a bash script: <code>[\"/bin/bash\", \"run.sh\"]</code>.</p> </li> <li> <p><code>requirements</code>: Specifies the requirements and dependencies of the tool:</p> </li> <li> <p><code>InlineJavascriptRequirement</code>: Allows the use of inline JavaScript expressions in the tool.</p> </li> <li><code>SchemaDefRequirement</code>: Ensures that specific types are defined and validated according to the referenced schemas. Custom types allow for reuse and better validation. Learn more.</li> <li><code>NetworkAccess</code>: Specifies that the tool requires outgoing network access. Only needed for <code>cwlVersion: v1.2</code>; in <code>v1.0</code> this is supported by default.</li> <li> <p><code>InitialWorkDirRequirement</code>: Defines files that must be staged before running the tool. Specifically:</p> <ul> <li>Creates <code>input_execute_request.json</code> containing the contents of <code>inputs.in_execute_request</code> converted to a pretty-printed JSON string:</li> </ul> <pre><code>listing:\n- entryname: input_execute_request.json\n  entry: |-\n      ${ return JSON.stringify(inputs.in_execute_request, null, 2); }\n</code></pre> <ul> <li>Creates <code>process_id.json</code> containing only the <code>process_id</code> from <code>inputs.in_execute_request</code>, also formatted as pretty-printed JSON:</li> </ul> <pre><code>listing:\n- entryname: process_id.json\n  entry: |-\n      ${ return JSON.stringify(inputs.in_execute_request.process_id, null, 2); }\n</code></pre> <ul> <li> <p>Creates <code>run.sh</code>, which performs the following actions when executed:</p> </li> <li> <p>Extracts STAC item URLs from the <code>search_results</code> JSON file and saves them to <code>stac_items.json</code>.</p> </li> <li>Deletes the <code>process_id</code> from <code>input_execute_request.json</code> and injects the extracted STAC items into the <code>.inputs.stac_items</code> field.</li> <li>Outputs the resulting <code>execute_request.json</code>, which can then be used as input for subsequent workflow steps.</li> </ul> </li> <li> <p><code>inputs</code>: Defines the input parameters for the tool.</p> </li> <li> <p><code>in_execute_request</code>: OGC API Processes settings (e.g., for Sentinel2/Landsat-9 data).</p> </li> <li> <p><code>search_results</code>: Discovery results from the prior step, provided as a file.</p> </li> <li> <p><code>outputs</code>: Defines the outputs produced by the tool.</p> </li> <li> <p><code>execute_request</code>: The final JSON request prepared for execution. An expample of this JSON file is mentioned below:     <pre><code>{\n    \"inputs\": {\n        \"stac_items\": [\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/landsat-c2-l2/items/LC08_L2SP_044032_20231208_02_T1\",\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/landsat-c2-l2/items/LC08_L2SP_043033_20231201_02_T1\"\n        ],\n        \"aoi\": \"-121.399,39.834,-120.74,40.472\",\n        \"epsg\": \"EPSG:4326\",\n        \"bands\": [\n            \"green\",\n            \"nir08\"\n        ]\n    }\n}\n</code></pre></p> </li> <li><code>process_id</code>: The original process identifier, preserved for reference.</li> </ul>"},{"location":"cwl-cli/scope/","title":"Scope","text":"<p>When developers package and EO, they are in fact packaging their own software, written in a specific programming language, as a containerized application (or a set of containerized applications), to be described as an EO Application Package using the Common Workflow Language as described in the OGC proposed best practices.</p> <p>To achieve this, developers follow the steps described below.</p> <p>Prepare one or more container images containing the execution dependencies of the software. Prepare the CWL CommandLineTool document(s) wrapping the command line tool available in container(s). Prepare the CWL Workflow orchestrating CWL CommandLineTool document(s) wrapping the command line tool available container(s). Test the application package in one or more execution scenarios. This section shows how to do the step:</p> <p>Prepare the CWL CommandLineTool document(s) wrapping the command line tool available container(s).</p>"},{"location":"cwl-workflow/eoap-api/","title":"EO application API Workflow","text":""},{"location":"cwl-workflow/eoap-api/#eoap-api-workflow-orchestrating-cwl-commandlinetools","title":"EOAP API Workflow - Orchestrating CWL CommandLineTools","text":"<p>The EOAP API Workflow chains together three main steps \u2014 <code>discovery</code>, <code>prepare-execute-request</code>, and <code>processes</code> \u2014 to query a STAC API, prepare an OGC API Processes execution request, and finally run the requested process.</p> <p>It takes the following input parameters:</p> <ul> <li>a STAC API endpoint</li> <li>a STAC search request (query parameters)</li> <li>a Processes API endpoint</li> <li>an execution request template for OGC API Processes</li> </ul> <p>And produces as outputs:</p> <ul> <li>the results of the STAC search (search results as a JSON file)</li> <li>the process execution result (OGC API Process output as a JSON file)</li> </ul> graph TB   A[STAC API Endpoint] --&gt; B((\"Discovery Step\"))   P[Search Request] --&gt; B   B --&gt; C1[Search Results]   C1 --&gt; C2[\"&lt;font size=2% color='blue'&gt;discovery-output.json&lt;/font&gt;\"]    C2 --&gt; D((\"Prepare Execute Request\"))   D --&gt; D2[\"&lt;pre style='text-align:left; color:black;'&gt; execute_request.json: {   inputs:     - stac_items     - aoi     - bands     - epsg } &lt;/pre&gt;\"]   D --&gt; D3[process_id.json]   D2 --&gt; E((\"Processes Step\"))   D3 --&gt; E   R[Processes API Endpoint] --&gt; E    E --&gt; F[Workflow Output]   C2 --&gt;F   F --&gt; I[\"&lt;font size=2% color='green'&gt;feature-collection.json&lt;/font&gt;\"]    F --&gt; G[\"&lt;font size=2% color='gray'&gt;discovery-output.json&lt;/font&gt;\"]    subgraph EOAP Workflow     B     C1     C2     D     D2     D3     E   end"},{"location":"cwl-workflow/eoap-api/#workflow-steps","title":"Workflow Steps","text":"<ol> <li> <p>Discovery Step    Uses the provided <code>stac_api_endpoint</code> and <code>search_request</code> to query a STAC API. The result is saved as <code>search_output</code>.</p> <ul> <li>Output: <code>discovery-output.json</code> \u2014 This JSON file contains the results from discovering the STAC endpoint. It is generated using <code>stac-api-client.0.1.0.cwl</code>.</li> </ul> </li> <li> <p>Prepare Execute Request Step    Combines the initial <code>execute_request</code> template with the <code>search_output</code> from the discovery step.</p> </li> <li> <p>Extracts STAC item URLs from the search results.</p> </li> <li>Inserts them into the <code>.inputs.stac_items</code> field of the execution request.</li> <li>Removes the <code>process_id</code> from the request and stores it separately.</li> <li> <p>Outputs:</p> <ul> <li><code>execute_request.json</code> \u2014 the updated request ready to be sent.</li> <li><code>process_id.json</code> \u2014 the process identifier.</li> </ul> </li> <li> <p>Processes Step    Executes the OGC API Process using the <code>processes_api_endpoint</code>, the prepared <code>execute_request.json</code>, and the <code>process_id</code>. The result is stored in <code>feature-collection.json</code>.</p> </li> </ol> <p>The CWL Workflow is shown below and the lines highlighted chain the steps:</p> eoap-api-cli.cwl<pre><code>#!/usr/bin/env cwl-runner\n\n$graph:\n- class: Workflow\n  id: eoap-api\n  label: EOAP API Workflow\n  requirements:\n  - class: InlineJavascriptRequirement\n  - class: SchemaDefRequirement\n    types:\n    - $import: https://raw.githubusercontent.com/eoap/schemas/main/string_format.yaml\n    - $import: https://raw.githubusercontent.com/eoap/schemas/main/geojson.yaml\n    - $import: |-\n        https://raw.githubusercontent.com/eoap/schemas/main/experimental/api-endpoint.yaml\n    - $import: https://raw.githubusercontent.com/eoap/schemas/main/experimental/discovery.yaml\n    - $import: https://raw.githubusercontent.com/eoap/schemas/main/experimental/process.yaml\n  - class: NetworkAccess\n    networkAccess: true\n  inputs:\n  - id: stac_api_endpoint\n    type: |-\n      https://raw.githubusercontent.com/eoap/schemas/main/experimental/api-endpoint.yaml#APIEndpoint\n  - id: search_request\n    type: |-\n      https://raw.githubusercontent.com/eoap/schemas/main/experimental/discovery.yaml#STACSearchSettings\n  - id: processes_api_endpoint\n    type: |-\n      https://raw.githubusercontent.com/eoap/schemas/main/experimental/api-endpoint.yaml#APIEndpoint\n  - id: execute_request\n    type: |-\n      https://raw.githubusercontent.com/eoap/schemas/main/experimental/process.yaml#OGCExecuteProcessSettings\n\n  outputs:\n  - id: search_output\n    outputSource:\n      - discovery/search_output\n    type: File\n  - id: process_output\n    outputSource:\n      - processes/process_output\n    type: File\n\n  steps:\n    discovery:\n      label: Discovery Step\n      in:\n        api_endpoint: stac_api_endpoint\n        search_request: search_request\n      run: https://github.com/eoap/schemas/releases/download/0.1.0/stac-api-client.0.1.0.cwl\n      out:\n      - search_output\n\n    prepare-execute-request:\n      label: Prepare Execute Request\n      in:\n        in_execute_request: execute_request\n        search_results:\n          source: discovery/search_output\n      run: '#prepare-execute-request'\n      out:\n      - execute_request\n      - process_id\n\n    processes:\n      label: Processes Step\n      in:\n        api_endpoint: processes_api_endpoint\n        execute_request: \n          source: prepare-execute-request/execute_request\n        process_id:\n          source: prepare-execute-request/process_id\n      run: '#ogc-api-processes-client'\n      out: \n      - process_output\n\n\n\n- class: CommandLineTool\n  id: prepare-execute-request\n  label: Prepare Execute Request\n  doc: Prepare the execute request for OGC API Processes based on search results \n\n  baseCommand: [\"/bin/bash\", \"run.sh\"]\n  arguments: []\n\n  requirements:\n  - class: InlineJavascriptRequirement\n  - class: SchemaDefRequirement\n    types:\n    - $import: https://raw.githubusercontent.com/eoap/schemas/main/string_format.yaml\n    - $import: https://raw.githubusercontent.com/eoap/schemas/main/geojson.yaml\n    - $import: |-\n        https://raw.githubusercontent.com/eoap/schemas/main/experimental/api-endpoint.yaml\n    - $import: https://raw.githubusercontent.com/eoap/schemas/main/experimental/process.yaml\n  - class: NetworkAccess\n    networkAccess: true\n  - class: InitialWorkDirRequirement\n    listing:\n    - entryname: input_execute_request.json\n      entry: |-\n        ${ return JSON.stringify(inputs.in_execute_request, null, 2); }\n    - entryname: process_id.json\n      entry: |-\n        ${ return JSON.stringify(inputs.in_execute_request.process_id, null, 2); }\n    - entryname: run.sh\n      entry: |-\n        #!/usr/bin/env bash\n        set -x\n        set -euo pipefail\n\n\n        jq '[.features[].links[] | select(.rel==\"self\") | .href]' \"$(inputs.search_results.path)\" &gt; stac_items.json\n\n        jq --argjson stac_items \"`cat stac_items.json`\" \\\n          'del(.process_id) | .inputs.stac_items = $stac_items' \\\n          input_execute_request.json &gt; execute_request.json\n\n        cat execute_request.json | jq .\n\n  inputs:\n    in_execute_request:\n      label: OGC API Processes settings\n      doc: OGC API Processes settings for Landsat-9 data\n      type: |-\n        https://raw.githubusercontent.com/eoap/schemas/main/experimental/process.yaml#OGCExecuteProcessSettings\n\n    search_results:\n      label: Search Results\n      doc: Search results from the discovery step\n      type: File\n\n  outputs:\n    execute_request:\n      type: File\n      outputBinding:\n        glob: execute_request.json\n    process_id:\n      type: Any\n      outputBinding:\n        glob: process_id.json\n        loadContents: true\n        outputEval: ${ return JSON.parse(self[0].contents); }\n\n\n\n- class: CommandLineTool\n  id: ogc-api-processes-client\n  label: geo API - Processes\n\n  requirements:\n  - class: InlineJavascriptRequirement\n  - class: DockerRequirement\n    dockerPull:  localhost/ogc \n  - class: SchemaDefRequirement\n    types:\n    - $import: https://raw.githubusercontent.com/eoap/schemas/main/string_format.yaml\n    - $import: https://raw.githubusercontent.com/eoap/schemas/main/geojson.yaml\n    - $import: |-\n        https://raw.githubusercontent.com/eoap/schemas/main/experimental/api-endpoint.yaml\n    - $import: https://raw.githubusercontent.com/eoap/schemas/main/experimental/process.yaml\n  inputs:\n    api_endpoint:\n      label: OGC API endpoint\n      doc: OGC API endpoint for Landsat-9 data\n      type: |-\n        https://raw.githubusercontent.com/eoap/schemas/main/experimental/api-endpoint.yaml#APIEndpoint\n    execute_request:\n      label: OGC API Processes settings\n      doc: OGC API Processes settings for Landsat-9 data\n      type: File\n    process_id:\n      label: Process ID\n      doc: Process ID for the OGC API Processes\n      type: Any\n\n  outputs:\n    process_output:\n      type: File\n      outputBinding:\n        glob: feature-collection.json\n  baseCommand: [\"ogc-api-processes-client\"]\n  arguments:\n    - --api-endpoint\n    - $(inputs.api_endpoint.url.value)\n    - --process-id\n    - $(inputs.process_id)\n    - --execute-request \n    - $(inputs.execute_request.path)\n    - --output\n    - feature-collection.json\n\n\ncwlVersion: v1.2\n</code></pre>"},{"location":"cwl-workflow/run-workflow/","title":"Running an OGC API Process with ZOO-Project","text":"<p>To invoke the OGC API process, follow these steps:</p> <ol> <li>Define the input parameters in YAML    Create a parameter file named <code>params.yaml</code>:</li> </ol> params.yaml<pre><code>stac_api_endpoint:\n  url:\n    value: https://planetarycomputer.microsoft.com/api/stac/v1\n  headers: []\n\nsearch_request:\n  collections: \n  - landsat-c2-l2\n  datetime_interval:\n    start:\n      value: \"2023-10-14T18:00:00\"\n    end:\n      value: \"2023-10-21T18:59:59\"\n  bbox: \n  - -121.399\n  - 39.834\n  - -120.74\n  - 40.472\n\n  filter-lang: cql2-json\n  filter:\n    {\n        \"op\": \"and\",\n        \"args\":\n          [\n            { \"op\": \"&lt;=\", \"args\": [{ \"property\": \"eo:cloud_cover\" }, 70] },\n            { \"op\": \"&gt;=\", \"args\": [{ \"property\": \"eo:cloud_cover\" }, 0] },\n            { \"op\": \"eq\" , \"args\": [{ \"property\": \"proj:epsg\"}, 32610]}\n          ],\n      }\n\n\nprocesses_api_endpoint:\n  url:\n    value: http://zoo-project-dru-service/acme/ogc-api/\n  headers: []\n\nexecute_request:\n  process_id: \"water-bodies\"\n  inputs:\n    aoi: \"-121.399,39.834,-120.74,40.472\"\n    bands:\n    - \"green\"\n    - \"nir08\"\n    epsg: \"EPSG:4326\"\n</code></pre> <ol> <li>Run the application package    Execute the process with <code>cwltool</code>:</li> </ol> <pre><code>cwltool --debug cwl-workflows/eoap-api-cli.cwl#eoap-api cwl-workflows/params.yaml \n</code></pre> <ol> <li>Inspect the results    The output is stored as a feature collection:</li> </ol> <pre><code>cat cwl-workflows/feature-collection.json\n</code></pre> <ol> <li>Retrieve one of the generated assets    Extract the root link from the feature collection, download the results, and display the directory tree:</li> </ol> <pre><code>results=$(jq -r '.features[0].links[] | select(.rel==\"root\") | .href' cwl-workflows/feature-collection.json | sed 's|/catalog.json$|/|')\n\naws s3 cp --recursive $results ./results/\n\ntree results\n</code></pre>"},{"location":"cwl-workflow/run-workflow/#expected-output","title":"Expected output","text":"<p>You should see logs of downloaded files followed by the resulting directory structure. For example:</p> <pre><code>download: s3://results/.../LC08_L2SP_043033_20231014_02_T1.json to results/.../LC08_L2SP_043033_20231014_02_T1.json\ndownload: s3://results/.../otsu.tif to results/.../otsu.tif\ndownload: s3://results/.../catalog.json to results/catalog.json\ndownload: s3://results/.../collection.json to results/.../collection.json\n...\n\nresults/\n|-- 932544e2-7f54-11f0-bd13-8a8eed839884\n|   |-- LC08_L2SP_043033_20231014_02_T1\n|   |   |-- LC08_L2SP_043033_20231014_02_T1.json\n|   |   `-- otsu.tif\n|   |-- LC08_L2SP_044032_20231021_02_T1\n|   |   |-- LC08_L2SP_044032_20231021_02_T1.json\n|   |   `-- otsu.tif\n|   `-- collection.json\n`-- catalog.json\n\n3 directories, 6 files\n</code></pre>"},{"location":"cwl-workflow/scope/","title":"Scope","text":"<p>When developers package and EO, they are in fact packaging their own software, written in a specific programming language, as a containerized application (or a set of containerized applications), to be described as an EO Application Package using the Common Workflow Language as described in the OGC proposed best practices.</p> <p>To achieve this, developers follow the steps described below.</p> <ul> <li>Prepare one or more container images containing the execution dependencies of the software.</li> <li>Prepare the CWL CommandLineTool document(s) wrapping the command line tool available in container(s).</li> <li>Prepare the CWL Workflow orchestrating CWL CommandLineTool document(s) wrapping the command line tool available container(s).</li> <li>Test the application package in one or more execution scenarios.</li> </ul> <p>This section shows how to do the step:</p> <ul> <li>Prepare the CWL Workflow orchestrating CWL CommandLineTool document(s) wrapping the command line tool available container(s).</li> </ul>"},{"location":"reference/ogc-api-processes-openapi/","title":"OGI API Processes swagger","text":""},{"location":"reference/ogc-api-processes/","title":"OGC API Processes","text":"<p>OGC API Processes overview: </p> <ul> <li> <p>https://ogcapi.ogc.org/processes/overview.html</p> </li> <li> <p>https://ogcapi.ogc.org/processes/</p> </li> </ul> <p>Github repository: https://github.com/opengeospatial/ogcapi-processes</p>"},{"location":"reference/zoo-project/","title":"ZOO-Project","text":"<p>The ZOO-Project is an open-source platform designed for implementing and deploying geospatial processing services based on the OGC API - Processes standard. </p> <p>It allows for the execution of complex geospatial workflows via web services, supporting interoperability by ensuring that various systems and tools can interact with the exposed processes regardless of the underlying technology. </p> <p>The OGC API - Processes standard, which is the evolution of the Web Processing Service (WPS), brings a more modern, flexible, and RESTful approach to managing and executing geospatial processes over the web.</p> <p>The ZOO-Project aims at ensuring that processing tasks follow the FAIR principles: Findable, Accessible, Interoperable, and Reproducible.</p> <p>The ZOO-Project supports the \"OGC API - Processes\" and implements the Web Processing Service (WPS) standards WPS 1.0.0 and WPS 2.0.0 edited by the OGC. </p> <p>More information on the ZOO-Project can be found on the official website: https://www.zoo-project.org/.</p>"}]}